% -*- TeX-master: "/home/joao/DOUTORADO/GIT/Qualificacao/Qualificacao.tex" -*-
%!TEX root = ../Qualificacao.tex

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                 EXAMPLE 4.1 (51) - 2nd Order System                 %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



% exemplo 51
\begin{exmp}[Second order Linear System -- continued.]\label{ex:sis2aord}

  Consider the 2nd-order linear system describe in Example \ref{exm:31}: 
  \begin{equation}
    \label{eq:sis2aord}
    y_k = a_1y_{k-1} + a_2y_{k-2} + b_1u_{k-1} + b_2u_{k-2}.
  \end{equation}
  % onde, para $i = 1,\ 2$, os termos $a_i$, $b_i$ $\in \R$, representam parâmetros constantes; $u_{k-i}$ e $y_{k-i}$ $\in \R$, os sinais de entrada e saída, respectivamente; e $k$ o índice temporal.
  According to the VRFT strategy (Chapter ~\ref{cap:VRFT}), one must first define a class of allowable controllers $\mathscr{C}$, containing the desired  structure, and define a reference model that expresses the desired close loop system's behavior.

  In this example, we want to analyze the use of the RAmSS algorithm directly, without modifications, in order to find the best structure for a controller designed from the VRFT strategy.
  In order to examine the behavior of the RaMSS Algorithm in finding the best set of regressors, we proceed as follows.

  A feasible reference model is defined, that is, with a relative degree equal to or greater than that of the process. For simplicity, a 1st order model with the same relative degree of the process is chosen, as Example \ref{exm:31}, given by the transfer function
  \begin{equation}
    M(z) = \frac{1-A}{z-A},
    \label{eq:mr_sis2aord}
  \end{equation}
  The parameter adopted here is the same as Exemple \ref{exm:31}, i.e. $A = -T_s/\tau_d = 0.8187$. 
  The ideal controller, represented by an ARX model, will be given by the structure composed of the regressors presented in \eqref{eq:exp31_uk}, represented here by
  \begin{equation}
    \label{eq:exp51_contIdeal}
    u_k = \theta_0e_{k} + \theta_1e_{k-1} + \theta_2e_{k-2} + \theta_3u_{k-1} + \theta_4u_{k-2},
  \end{equation}
  and will have the parameters shown in \eqref{eq:exp31_ideal_parameters}, described here as
  \begin{equation}
    \vtheta^\star= \begin{bmatrix} \theta^\star_0 & \theta^\star_1 & \theta^\star_2 & \theta^\star_3 & \theta^\star_4 \end{bmatrix}^T =  \begin{bmatrix} 0.181 & 0.308 &  0.145 &  0.19 & 0.81 \end{bmatrix}^T.
  \label{eq:ex51_ideal_parameters}
\end{equation}
Using the RaMSS algorithm, as discussed in the section ~\ref{sec:ramss}, the procedure is performed for 2 cases:
\begin{description}
  \item[case A] the universe set $\mathscr{M}$ is taken as all possible 3rd degree non linear models formed by the monomials up to 4 delays for input $\tilde{e}_k$ (virtual error) and output $\tilde{u}_k$ (virtual process input) collected data. No noise is considered in this case.
  \item[case B] the same case as case A, but now with a noise in the output, given by a gaussian distribution, i.e. $\nu \sim \mathcal{N}(\mu,\sigma)$, where $\mu=0$ is the mean, and $\sigma= 0.1$ is the standard deviation adopted. Note that the noise is added in the output, in a way that the model for the process is represented by an output error model (OEM).
\end{description}
The RaMSS procedure is applied to a data set of 700 samples, obtained via the VRFT procedure, in which the VRFT filter is considered to be unitary, i.e. the data is not filtered. The same data set is applied for the 2 cases. At each iteration, 100 candidate models are randomly chosen to be analyzed, using a Bernoulli process. The RIPs are updated in a maximum of 100 iterations, or until they all converge to a margin above 0.9 or below 0.1, i.e. the following stopping criterion is adopted:
\begin{align}
  \textbf{if } \left[iter<iter_{\max}\right] \textbf{ or } \left[\Delta_S < \frac{1}{2} \left(1-\min_{\forall \mu \in \bm{\mu}_k}{ \left| 2\mu -1 \right| }\right)\right] \textbf{ then} \text{, STOP the procedure.}
\label{eq:crit.par}
\end{align}
where $\Delta_S = 0.1$ is the convergence margin, $iter$ is the iteration number and $iter_{\max} = 100$ is the maximum allowed iterations.


Applying the procedure in both cases, the following controllers are obtained, for a specific realization:
\begin{align}
  % Para caso 24:
  \label{eq:ex51CasesAB}
  u_1(k) &= 0.636{u}_1(k-1) + 0.513{u}_1(k-2) + -0.321{u}_1(k-3) + 0.17{u}_1(k-4) \nonumber\\
      &\quad+ 0.181{e}_1(k) + 0.227{e}_1(k-1) + 0.045{e}_1(k-2) + 0.03{e}_1(k-4) \\
  u_2(k) &= 0.737{u}_2(k-1) + 0.242{u}_2(k-2) + -0.329{u}_2(k-3) + 0.32{u}_2(k-4) \nonumber\\
         &+ 0.175{e}_2(k) + 0.197{e}_2(k-1) + 0.049{e}_2(k-2) + 0.049{e}_2(k-3) + 0.059{e}_2(k-4)
  % u_1(k) &= 0.193{u}_1(k-1) + 0.805{u}_1(k-2)  \nonumber \\
         % &\quad + 0.001{u}_1(k-3) + 0.181{e}_1(k) + 0.307{e}_1(k-1) + 0.144{e}_1(k-2) \nonumber \\
  % u_2(k) &= 0.737{u}_2(k-1) + 0.242{u}_2(k-2) + -0.329{u}_2(k-3) + 0.32{u}_2(k-4)  \\
         % &\quad + 0.175{e}_2(k) + 0.  97{e}_2(k-1) + 0.049{e}_2(k-2) + 0.049{e}_2(k-3) + 0.059{e}_2(k-4)  \nonumber
  % u_1(k) &= 0.193{u}_1(k-1) + 0.805{u}_1(k-2) + 0.001{u}_1(k-3) \\
         % &+ 0.181{e}_1(k) + 0.307{e}_1(k-1) + 0.1441{e}(k-2), \\
  % u_2(k) &= 0.751{u}_2(k-1) + 0.241{u}_2(k-2) -0.33{u}_2(k-3) + 0.322{u}_2(k-4) \\
         % &+ 0.174{e}_2(k) + 0.197{e}_2(k-1) + 0.048{e}_2(k-2) + 0.049{e}_2(k-3) + 0.0591,
\end{align}
where the index subscribed to the variables represent the respective cases.

The table ~\ref{tab:exp51_param} sumarizes the simulation parameters used in \ref{alg:RaMSS}, for the 2 cases,
where $o$ is the maximum allowed degree for the regressors, $n_{\tilde{e}}$ is the maximum delay for the virtual error signal $\tilde{e}(k)$, $n_{\tilde{u}}$ is the maximum delay for the input signal of the sampled plant, $ N_p$ is the number of models chosen at each update of the RIPs, $ iter_{\max} $ is the maximum number of allowed iterations, $\Delta_S$ is the trashold for convergence of RIPs, $K$ is the gain for the performance indexes presented in \ref{eq:Js}, $\gamma_0$ is the initial gain of \ref{eq:gamma}, $\mu_{\min}$ and $\mu_{\max}$ are the minumum and maximum values allowed for the RIPs and $\nu$ is the noise added to the output.
\begin{table}[htpb]
  \centering
  \caption{Parameters for simulating the RaMSS algorithm of the example ~\ref{ex:sis2aord}}\label{tab:exp51_param}
  \begin{tabular}{c|c|c|c|c|c|c|c|c|c|c}
    Case & $o$ & $n_{\tilde{e}}$ & $n_{\tilde{u}}$ & $ N_p$ & $ iter_{\max} $ & $K$ & $\gamma_0$ &  $\mu_{\min}$ & $\mu_{\max}$ & $\nu$\\
    \hline
    A & $ 3 $ & $4$ & $4$ & $100$ & $100$ & $1$ & $2$ & $0.05$ & $1$ & $0$ \\
    B & $ 3 $ & $4$ & $4$ & $100$ & $100$ & $1$ & $2$ & $0.05$ & $1$ & $\mathcal{N}(\mu,\sigma)$
  \end{tabular}
\end{table}\\
\todo[inline]{MEXER NESTA TABELA AINDA! Valores estão errados. Já os modifiquei. Definir parâmetros, etc. Colocar os mais essenciais por aqui e os menos, no appendice. }

Note that the controllers presented in~\eqref{eq:ex51CasesAB} are obtained for a specific realization of the procedure. All terms that end with the RIP above 0.95 are considered in the hundredth iteration.
Figure \ref{fig:ex51_RIPevol_2cases} shows the evolution of the RIPs for this realization.

\begin{figure}[H]
  \centering
  % \includegraphics[width=\textwidth]{Figs/Cap5/ex51_rips_evol_2cases.tex.pdf}
  \includegraphics[width=\textwidth]{Figs/Cap5/ex51_rips.tex.pdf}
  \caption{Typical evolution of RIPs for choosing regressors for case 1 and 2.}
  \label{fig:ex51_RIPevol_2cases}
\end{figure}
\todo[inline]{Trocar esta figura} 

The ideal regressors are selected before the first 40 steps.
But as the iterations continue, the $\tilde{u}(k-3)$, $\tilde{u}(k-4)$ and $\tilde{e}(k-4)$ regressors continue to increase monotonically in value and eventually end up being selected.
The effect of including these terms, although in general they are small, deteriorates the desired behavior of the controller.
When considering noise in the measurement (case 2), the selection of non-ideal regressors occurs even earlier, as can be seen in the lower graph of \ref{fig:ex51_RIPevol_2cases}.
Part of this result is due to the worsening of parametric identification during the VRFT procedure, provoked by the polarization effect introduced by noise at the output. The result is that the regressor vectors are no longer orthogonal to the residuals and the OLS estimator becomes polarized. A strategy to mitigate this effect is to use non-polarized estimators, such as VI estimators, or even the ELS.

Figure ~\ref{fig:Figs-RespostaSist2aordNARX-png} shows the temporal response for the controllers identified in \eqref{eq:ex51CasesAB}, when the reference signal is taken as a square wave.

% The figure  shows the temporal response for a square wave in reference signal, for the 2 cases.
% Note que no Caso 1,

\begin{figure}[H]
  \sbox0{\blacksolidlinethin} \sbox1{\bluedashedline} \sbox2{\reddottedline} \sbox3{\blackdottedline} \sbox4{\bluedashdotedline} 
  \centering
  % \includegraphics[width=1\textwidth]{./Figs/Cap5/ex51_resp_temporal_mf_editado.tex.pdf}
  \includegraphics[width=1\textwidth]{./Figs/Cap5/ex51_resp_temporal_mf2.tex.pdf}
  % \include{./Figs/Cap5/ex51_resp_temporal_mf.tex}
  % \caption{Resposta do sistema em malha fechada (gráfico superior) e respectivos erros absolutos (gráfico inferior) utilizando os controladores identificados no caso A (\usebox1) e no caso B (\usebox2). Os sinais de referência (\usebox3) e de reposta do modelo de de referência (\usebox0) são mostrados no gráfico superior. O erro para caso considerando somente a estrutura ideal é representado por (\usebox4), no gráfico inferior.}
  \caption{Closed-loop system response (upper graph) and respective absolute errors (lower graph) using the controllers identified in case A (\usebox1) and case B (\usebox2). The reference (\usebox3) and the reference model response (\usebox0)  signals are shown in the upper graph. The error for case considering only the ideal structure is represented by (\usebox4), in the lower graph.}
  \label{fig:Figs-RespostaSist2aordNARX-png}
\end{figure}

The behavior of the case with noise is deteriorated in relation to case 1 (without noise). The steady-state error for case 2 is about 10 times greater than case 1, as shown in the lower graph in Figure \ref{fig:Figs-RespostaSist2aordNARX-png} (note the different scales in the error graph in the figure).
This greater error is due to two factors: selection of an over-parameterized structure of the model by the RaMSS procedure, and worse parametric identification due to the presence of noise at the output, which can result in parameter polarization.
Note that, as the noise is added to the process output (OEM), and by the procedure of filtering by the inverse of the plant when applying the VRFT, the noise, although white, can cause polarization in the identified parameters.
The error graph in Figure \ref{fig:Figs-RespostaSist2aordNARX-png} also shows the time response for the case without noise, but considering that only the ideal regressors are taken into account in the identification process.
In this case, the error decreases, and and this decrease is attributed to the over parameterization caused by the extra regressors selected in case 1.
Despite this, a small error remains on steady state. This fact is attributed to the effect discussed in Chapter \ref{cap:VRFT}, in which small errors in the identification of parameters make the sum of the coefficients in $y(k)$ not exactly zero, resulting in a system with high gain at low frequencies, but not infinite. As discussed, in the chapter \ref{cap:VRFT} and to be proposed in the chapter \ref{cap:Concl}, it is hoped that this problem can be solved by imposing restrictions on the identification process (use of auxiliary information).



\todo[inline]{Ainda em construção, por enquanto só coloquei alguns dos gráficos que irei utilizar. Comparações, com tabelas comparando resultados do RaCSS com o ERR também serão ainda colocados. Logicamente, com devidas análises.}

\end{exmp}




