
@article{aguirre1994,
  title = {Some Remarks on Structure Selection for Nonlinear Models},
  author = {Aguirre, Luis Antonio},
  year = {1994},
  month = dec,
  volume = {04},
  pages = {1707--1714},
  issn = {0218-1274},
  doi = {10.1142/S0218127494001325},
  journal = {International Journal of Bifurcation and Chaos},
  keywords = {PT,PT2},
  number = {06}
}

@book{aguirre2015,
  title = {Introdu\c{c}\~ao \`a Identifica\c{c}\~ao de Sistemas: T\'ecnicas Lineares e N\~ao Lineares: Teoria e Aplica\c{c}\~ao},
  author = {Aguirre, Luis Antonio},
  year = {2015},
  edition = {Fourth},
  address = {{Belo Horizonte}},
  isbn = {978-85-423-0079-6},
  keywords = {PT,PT2}
}

@article{albus1971,
  title = {A Theory of Cerebellar Function},
  author = {Albus, James S.},
  year = {1971},
  volume = {10},
  pages = {25--61},
  issn = {00255564},
  doi = {10.1016/0025-5564(71)90051-4},
  journal = {Mathematical Biosciences},
  keywords = {PT,PT1},
  language = {en},
  number = {1-2}
}

@article{andrei2006,
  title = {Modern Control Theory - a Historical Perspective},
  author = {Andrei, Neculai},
  year = {2006},
  pages = {51--62},
  doi = {10.1007/3-540-28087-1},
  isbn = {3-540-23951-0},
  journal = {Studies in Informatics and Control},
  keywords = {PT,PT2},
  number = {10}
}

@book{astrom1995,
  title = {{{PID}} Controllers: {{Theory}} Design and Tuning},
  author = {Astrom, Karl Johan},
  year = {1995},
  edition = {Second},
  publisher = {{Instruments Society of America}},
  address = {{North Carolina, USA}},
  keywords = {PT,PT2}
}

@phdthesis{barroso2006,
  title = {Otimiza\c{c}\~ao Bi-Objetivo Apliada \`a Estima\c{c}\~ao de Par\^ametros de Modelos N\~ao-Lineares: Carateriza\c{c}\~ao e Tomada de Decis\~ao},
  author = {Barroso, M{\'a}rio F. Santos},
  year = {2006},
  pages = {134},
  abstract = {A identifica\c{c}\~ao de sistemas compreende um conjunto de t\'ecnicas para a modelagem de sistemas din\^amicos. Essas t\'ecnicas, normalmente, s\~ao classificadas de acordo com a utiliza\c{c}\~ao ou n\~ao de informa\c{c}\~oes contidas em dados medidos. De maneira geral, a identifica\c{c}\~ao de sistemas pode ser dividida em cinco partes, destacando-se: (i) escolha de representa\c{c}\~ao, (ii) detec\c{c}\~ao de estrutura, (iii) estima\c{c}\~ao de par\^ametros e (iv) valida\c{c}\~ao do modelo. A teoria b\'asica encontra-se muito bem fundamentada e com um grande n\'umero de trabalhos que a utiliza como base para o desenvolvimento de ferramentas matem\'aticas e computacionais. A detec\c{c}\~ao de estrutura, classicamente, utiliza a an\'alise de res\'iduos, ou seja, erro de um passo \`a frente, como \'indice de desempenho. Embora ainda sejam largamente utilizados, alguns trabalhos sugerem que tais ferramentas apresentem compensa\c{c}\~ao a prov\'aveis erros estruturais, ou seja, a erro na escolha dos regressores. \'E sugerido, a partir disso, que sejam utilizados \'indices baseados no erro de simula\c{c}\~ao e n\~ao residual. O presente trabalho pretende abstrair tais sugest\~oes para o caso da estima\c{c}\~ao de par\^ametros, utilizando um estimador bi-objetivo, em que a etapa de decis\~ao utilize an\'alise do erro de simula\c{c}\~ao do modelo como \'indice de desempenho. A estrutura ser\'a considerada conhecida. Este trabalho tem por objetivo argumentar, com base em simula\c{c}\~oes e an\'alise matem\'atica, que estimadores bi-objetivo, com certas caracter\'isticas estruturais, tais como, linearidade nos par\^ametros e convexidade, s\~ao capazes de retornar um conjunto de modelos, que apresente distribui\c{c}\~ao estat\'istica semelhante a estimadores tradicionais. A partir disso, ser\'a demonstrado tamb\'em que \'e poss\'ivel determinar qual dos modelos apresenta valores de par\^ametros mais pr\'oximo dos valores reais, ou seja, n\~ao-polarizados. Essa decis\~ao \'e feita atrav\'es de t\'ecnicas de correla\c{c}\~ao. V\'arios exemplos no decorrer do texto ser\~ao utilizados para validar as t\'ecnicas desenvolvidas. A caracteriza\c{c}\~ao e a tomada de decis\~ao de estimadores bi-objetivo n\~ao-polarizados formam o conjunto de contribui\c{c}\~oes desta tese.},
  keywords = {PT,PT2},
  school = {UFMG}
}

@article{bazanella2008a,
  title = {Iterative Minimization of {{H}}{$_2$} Control Performance Criteria},
  author = {Bazanella, Alexandre S. and Gevers, Michel and Mi{\v s}kovi{\'c}, Ljubi{\v s}a and Anderson, Brian D.O.},
  year = {2008},
  month = oct,
  volume = {44},
  pages = {2549--2559},
  issn = {00051098},
  doi = {10.1016/j.automatica.2008.03.014},
  abstract = {Data-based control design methods most often consist of iterative adjustment of the controller's parameters towards the parameter values which minimize an H2performance criterion. Typically, batches of input-output data collected from the system are used to feed directly a gradient descent optimization - no process model is used. A limiting factor in the application of these methods is the lack of useful conditions guaranteeing convergence to the global minimum; several adaptive control algorithms suffer from the same limitation. In this paper the H2performance criterion is analyzed in order to characterize and enlarge the set of initial parameter values from which a gradient descent algorithm can converge to its global minimum. \textcopyright{} 2008.},
  journal = {Automatica},
  keywords = {Data-based control design,H2performance criteria,PT,PT2},
  number = {10}
}

@book{bazanella2012,
  title = {Data-Driven Controller Design},
  author = {Bazanella, Alexandre Sanfelice and Campestrini, Luc{\'i}ola and Eckhard, Diego},
  year = {2012},
  pages = {208},
  publisher = {{Springer Netherlands}},
  address = {{Dordrecht}},
  issn = {9783540707820},
  doi = {10.1007/978-94-007-2300-9},
  abstract = {Data-driven methodologies have recently emerged as an important paradigm alternative to model-based controller design and several such methodologies are formulated as an H2 performance optimization. This book presents a comprehensive theoretical treatment of the H2 approach to data-driven control design. The fundamental properties implied by the H2 problem formulation are analyzed in detail, so that common features to all solutions are identified. Direct methods (VRFT) and iterative methods (IFT, DFT, CbT) are put under a common theoretical framework. The choice of the reference model, the experimental conditions, the optimization method to be used, and several other designer's choices are crucial to the quality of the final outcome, and firm guidelines for all these choices are derived from the theoretical analysis presented. The practical application of the concepts in the book is illustrated with a large number of practical designs performed for different classes of processes: thermal, fluid processing and electromechanical. Covers data-driven control design, using four different data-driven design methodologies: VRFT, IFT, DFT, CbT; Employs both theoretical formalism and practical insights; Provides experimental results illustrating the application of the methodologies for the main classes of processes found in industry: mechanical, thermal, and fluid processing; Analyzes design choices in depth; processes demonstrated such that readers easily can connect the results obtained with the theory presented; Enables readers to understand the potential and limitations of each data-driven methodology for his/her particular application, chose the best methodology for his/her application, and code it with the appropriate design choices.},
  archivePrefix = {arXiv},
  arxivid = {arXiv:1011.1669v3},
  eprint = {1011.1669v3},
  eprinttype = {arxiv},
  isbn = {978-94-007-2299-6},
  keywords = {PT,PT2},
  pmid = {25246403},
  series = {Communications and Control Engineering}
}

@article{bazanella2014a,
  title = {Tuning Nonlinear Controllers with the Virtual Reference Approach},
  author = {Bazanella, Alexandre Sanfelice and Neuhaus, Tassiano},
  year = {2014},
  volume = {47},
  pages = {10269--10274},
  publisher = {{IFAC}},
  issn = {14746670},
  doi = {10.3182/20140824-6-ZA-1003.00562},
  isbn = {9783902823625},
  journal = {IFAC Proceedings Volumes},
  keywords = {auto-tuning,identification,nonlinear systems,process control,PT,PT2},
  number = {3}
}

@book{bellmann1957,
  title = {Dynamic {{Programming}}},
  author = {Bellmann, Richard E.},
  year = {1957},
  publisher = {{Princeton University Press.}},
  address = {{Princeton, New Jersey}},
  keywords = {PT,PT1}
}

@article{bertsekas1982,
  title = {Distributed Dynamic Programming},
  author = {Bertsekas, D.},
  year = {1982},
  month = jun,
  volume = {27},
  pages = {610--616},
  issn = {0018-9286},
  doi = {10.1109/TAC.1982.1102980},
  file = {/home/joao/GDRIVE/Zotero/1982-bertsekas-distributed_dynamic_programming.pdf},
  journal = {IEEE Transactions on Automatic Control},
  keywords = {PT,PT1},
  language = {en},
  number = {3}
}

@book{bertsekas1987,
  title = {Dynamic Programming: Deterministic and Stochastic Models},
  shorttitle = {Dynamic Programming},
  author = {Bertsekas, Dimitri P.},
  year = {1987},
  publisher = {{Prentice-Hall}},
  address = {{Englewood Cliffs, N.J}},
  isbn = {978-0-13-221581-7},
  keywords = {Dynamic programming,PT,PT1},
  lccn = {T57.83 .B484 1987}
}

@book{bertsekas1996,
  title = {Neuro-Dynamic Programming},
  author = {Bertsekas, Dimitri P. and Tsitsiklis, John N.},
  year = {1996},
  publisher = {{Athena Scientific}},
  address = {{Belmont, Mass}},
  isbn = {978-1-886529-10-6},
  keywords = {Dynamic programming,Mathematical optimization,Neural networks (Computer Science),PT,PT1},
  lccn = {QA76.87 .B47 1996},
  series = {Optimization and Neural Computation Series}
}

@book{bertsekas2019,
  title = {Reinforcement Learning and Optimal Control},
  author = {Bertsekas, Dimitri P},
  year = {2019},
  edition = {1st},
  publisher = {{Athena Scientific}},
  isbn = {978-1-886529-39-7},
  keywords = {PT,PT1,R20_1,RL},
  language = {English}
}

@article{bu2012a,
  title = {Robust Model Free Adaptive Control with Measurement Disturbance},
  author = {Bu, X. and Hou, Z. and Yu, F. and Wang, F.},
  year = {2012},
  month = jun,
  volume = {6},
  pages = {1288},
  issn = {17518644},
  doi = {10.1049/iet-cta.2011.0381},
  abstract = {This study discusses the robustness of model free adaptive control (MFAC) algorithms. It is shown that the robust stability of MFAC system with bounded measurement disturbance can be guaranteed, and the bound on tracking error depends on the bound on the measurement disturbance. The statistical analysis approach is also introduced to investigate the influence of measurement disturbance. Then, a modified MFAC algorithm with decreasing gain is proposed. Theoretical analysis indicates that the proposed algorithm can attenuate measurement disturbance effectively and obtain better output performance. The analysis is supported by simulations. \textcopyright{} 2012 The Institution of Engineering and Technology.},
  journal = {IET Control Theory \& Applications},
  keywords = {PT,PT2},
  number = {9}
}

@book{busoniu2017,
  title = {Reinforcement {{Learning}} and {{Dynamic Programming Using Function Approximators}}},
  author = {Busoniu, Lucian and Babuska, Robert and Schutter, Bart De and Ernst, Damien},
  year = {2017},
  publisher = {{CRC Press}},
  abstract = {From household appliances to applications in robotics, engineered systems involving complex dynamics can only be as effective as the algorithms that control them. While Dynamic Programming (DP) has provided researchers with a way to optimally solve decision and control problems involving complex dynamic systems, its practical value was limited by algorithms that lacked the capacity to scale up to realistic problems.  However, in recent years, dramatic developments in Reinforcement Learning (RL), the model-free counterpart of DP, changed our understanding of what is possible. Those developments led to the creation of reliable methods that can be applied even when a mathematical model of the system is unavailable, allowing researchers to solve challenging control problems in engineering, as well as in a variety of other disciplines, including economics, medicine, and artificial intelligence.  Reinforcement Learning and Dynamic Programming Using Function Approximators provides a comprehensive and unparalleled exploration of the field of RL and DP. With a focus on continuous-variable problems, this seminal text details essential developments that have substantially altered the field over the past decade. In its pages, pioneering experts provide a concise introduction to classical RL and DP, followed by an extensive presentation of the state-of-the-art and novel methods in RL and DP with approximation. Combining algorithm development with theoretical guarantees, they elaborate on their work with illustrative examples and insightful comparisons. Three individual chapters are dedicated to representative algorithms from each of the major classes of techniques: value iteration, policy iteration, and policy search. The features and performance of these algorithms are highlighted in extensive experimental studies on a range of control applications.  The recent development of applications involving complex systems has led to a surge of interest in RL and DP methods and the subsequent need for a quality resource on the subject. For graduate students and others new to the field, this book offers a thorough introduction to both the basics and emerging methods. And for those researchers and practitioners working in the fields of optimal and adaptive control, machine learning, artificial intelligence, and operations research, this resource offers a combination of practical algorithms, theoretical analysis, and comprehensive examples that they will be able to adapt and apply to their own work.  Access the authors' website at www.dcsc.tudelft.nl/rlbook/ for additional material, including computer code used in the studies and information concerning new developments.},
  annotation = {ZSCC: NoCitationData[s2]},
  googlebooks = {xpwuDwAAQBAJ},
  isbn = {978-1-351-83382-0},
  keywords = {Computers / Machine Theory,PT,PT1,RL,Technology \& Engineering / Electrical,Technology \& Engineering / Electronics / General},
  language = {en}
}

@article{campestrini2016a,
  title = {Unbiased {{MIMO VRFT}} with Application to Process Control},
  author = {Campestrini, Luc{\'i}ola and Eckhard, Diego and Ch{\'i}a, Lydia Andrea and Boeira, Emerson},
  year = {2016},
  month = mar,
  volume = {39},
  pages = {35--49},
  issn = {09591524},
  doi = {10.1016/j.jprocont.2015.12.010},
  abstract = {Continuous process industries usually have hundreds to thousands of control loops, most of which are coupled, i.e. one control loop affects the behavior of another control loop. In order to properly design the controllers and reduce the interactions between loops it is necessary to consider the multivariable structure of the process. Usually MIMO (multiple-input, multiple-output) controllers are designed using MIMO models of the process, but obtaining these models is a task very demanding and time consuming. Virtual Reference Feedback Tuning (VRFT) is a data-driven technique to design controllers which do not use a model of the process; all the needed information is collected from input/output data from an experiment. The method is well established for SISO (single-input, single-output) systems and there are some extensions to MIMO process which assume that all the outputs should have the same closed-loop performance. In this paper we develop a complete framework to MIMO VRFT which provides unbiased estimates to the optimal MIMO controller (when it is possible) even when the closed-loop performances are distinct to each loop. When it is not possible to obtain the optimal controller because the controller class is too restrictive (for example PID controllers) then we propose the use of a filter to reduce the bias on the estimates. Also, when the data is corrupted by noise, the use of instrumental variables to eliminate the bias on the estimate should be considered. The article presents simulation examples and a practical experiment on a tree tank system where the goal is to control the level of two tanks.},
  journal = {Journal of Process Control},
  keywords = {Data-driven control,MIMO processes,PID control,PT,PT2,VRFT}
}

@article{campi2002,
  ids = {campi2002b},
  title = {Finite Sample Properties of System Identification Methods},
  author = {Campi, Marco C. and Weyer, Erik},
  year = {2002},
  volume = {47},
  pages = {1329--1334},
  publisher = {{IEEE}},
  issn = {00189286},
  doi = {10.1109/TAC.2002.800750},
  abstract = {In this paper we study the quality of system identification models obtained using the standard quadratic prediction error criterion for a general linear model class. The main feature of our results is that they hold true for a finite data sample and they are not asymptotic. The main theorems bound the difference between the expected value of the identification criterion evaluated at the estimated parameters and at the optimal parameters. The bound depends naturally on the model and system order, the pole locations, and the noise variance, and it shows that although these variables often do not enter in asymptotic convergence results, they do play an important role when the data sample is finite.},
  annotation = {ZSCC: 0000074},
  file = {/home/joao/GDRIVE/Zotero/2002-campi_weyer-finite_sample_properties_of_system_identification_methods.pdf},
  isbn = {0018-9286 VO - 47},
  journal = {IEEE Transactions on Automatic Control},
  keywords = {DD,Finite sample,Nonasymptotic theory,Prediction error methods,PT,PT1,R20_1,RL,System identification,VRFT},
  number = {8}
}

@article{campi2002b,
  title = {Virtual Reference Feedback Tuning: A Direct Method for the Design of Feedback Controllers},
  author = {Campi, M.C. and Lecchini, A. and Savaresi, S.M.},
  year = {2002},
  volume = {38},
  pages = {1337--1346},
  issn = {00051098},
  doi = {10.1016/S0005-1098(02)00032-8},
  abstract = {This paper considers the problem of designing a controller for an unknown plant based on input/output measurements. The new design method we propose is direct (no model identification of the plant is needed) and can be applied using a single set of data generated by the plant, with no need for specific experiments nor iterations. It is shown that the method searches for the global optimum of the design criterion and that, in the case of restricted complexity controller design, the achieved controller is a good approximation of the restricted complexity global optimal controller. A simulation example shows the effectiveness of the method.},
  isbn = {9783902823625},
  journal = {Automatica},
  keywords = {data-based controller design,direct control,pid tuning,PT,PT2},
  number = {8}
}

@article{campi2006a,
  title = {Direct Nonlinear Control Design: {{The}} Virtual Reference Feedback Tuning ({{VRFT}}) Approach},
  author = {Campi, M.C. Marco C. and Savaresi, S.M. Sergio M.},
  year = {2006},
  month = jan,
  volume = {51},
  pages = {14--27},
  issn = {00189286},
  doi = {10.1109/TAC.2005.861689},
  abstract = {This paper introduces the virtual reference feedback tuning (VRFT) approach for controller tuning in a nonlinear setup. VRFT is a data-based method that permits to directly select the controller based on data, with no need for a model of the plant. It is based on a global model reference optimization procedure and, therefore, does not require to access the plant for experiments many times so as to estimate the control cost gradient. For this reason, it represents a very appealing controller design methodology for many control applications.},
  journal = {IEEE Transactions on Automatic Control},
  keywords = {Controller tuning,Data-based tuning,Direct control,Model reference control,Nonlinear systems,PT,PT2},
  number = {1}
}

@article{chan1996,
  title = {Data-Based Control System Synthesis: {{A}} Discrete Domain Formulation for Redundantly Actuated Systems},
  author = {Chan, J-TH},
  year = {1996},
  volume = {24},
  pages = {22--27},
  publisher = {{ACTA Press}},
  issn = {0730-9538},
  abstract = {A numerical approach is presented for synthesizing a linear discrete system controller base on plant input and output data. The method is applicable when the system is open-loop stable and redundantly actuated. The major merits of the method are (1) the closed-loop system equation may be arbitrarily placed, (2) explicit identification of a parameterized plant model is not required, and (3) the stability of the designed system can be verified even though the plant model is unknown.},
  journal = {Control and computers},
  keywords = {PT,PT2},
  number = {1}
}

@article{chan1996experimental,
  title = {Experimental Data-Based Control System Synthesis: {{A}} Continuous Domain Formulation for Minimum-Phase Systems},
  author = {Chan, J-TH},
  year = {1996},
  volume = {24},
  pages = {1--5},
  publisher = {{ACTA Press}},
  abstract = {A numerical method is proposed to synthesize a feedback control system from open-loop plant test data. The method is applicable when the system is open-loop stable and minimum phase. The merits of the method are (1) the closed-loop system equation may be arbitrarily assigned; (2) explicit knowledge of a parameterized plant model is not needed for the design; and (3) the closed-loop stability of the design can be verified during the design process even though the plant model has not yet been identified.},
  journal = {Control and computers},
  keywords = {PT,PT2},
  number = {1}
}

@article{chen2008,
  title = {Iterative Learning Control and Repetitive Control in Hard Disk Drive Industry--{{A}} Tutorial},
  author = {Chen, YangQuan and Moore, Kevin L. and Yu, Jie and Xu, Jian-Xin},
  year = {2008},
  volume = {22},
  pages = {325--343},
  issn = {08906327},
  doi = {10.1002/acs},
  abstract = {In this paper, a sensor fault detection and isolation scheme for nonlinear systems is considered. A nonlinear diffeomorphism is introduced to explore the system structure and a simple filter is presented to `transform' the sensor fault into a pseudo-actuator fault scenario. A sliding mode observer is designed to reconstruct the sensor fault precisely if the system does not experience any uncertainty, and to estimate the sensor fault when uncertainty exists. The reconstruction and estimation signals are based only on available information and thus can be implemented online. Finally, a mass\textendash spring system is used to illustrate the approach.},
  arxiv = {LPV\_Xiaohang\_2015},
  arxivid = {LPV\textsubscript{X}iaohang{$_2$}015},
  isbn = {9783902661289},
  journal = {International Journal of Adaptive Control and Signal Processing},
  keywords = {fault detection and isolation,nonlinear observers,PT,PT2,sliding modes},
  number = {4}
}

@article{chunmiao2012,
  title = {Control and Research Based on Data-Driven {{Virtual}} Feedback Algorithms},
  author = {Chunmiao, Xi},
  year = {2012},
  isbn = {9780956715715},
  keywords = {PT,PT2}
}

@article{dean2017,
  title = {On the {{Sample Complexity}} of the {{Linear Quadratic Regulator}}},
  author = {Dean, Sarah and Mania, Horia and Matni, Nikolai and Recht, Benjamin and Tu, Stephen},
  year = {2017},
  doi = {arXiv:1710.01688v3},
  abstract = {This paper addresses the optimal control problem known as the Linear Quadratic Regulator in the case when the dynamics are unknown. We propose a multi-stage procedure, called Coarse-ID control, that estimates a model from a few experimental trials, estimates the error in that model with respect to the truth, and then designs a controller using both the model and uncertainty estimate. Our technique uses contemporary tools from random matrix theory to bound the error in the estimation procedure. We also employ a recently developed approach to control synthesis called System Level Synthesis that enables robust control design by solving a convex optimization problem. We provide end-to-end bounds on the relative error in control cost that are nearly optimal in the number of parameters and that highlight salient properties of the system to be controlled such as closed-loop sensitivity and optimal control magnitude. We show experimentally that the Coarse-ID approach enables efficient computation of a stabilizing controller in regimes where simple control schemes that do not take the model uncertainty into account fail to stabilize the true system.},
  annotation = {ZSCC: 0000000},
  archivePrefix = {arXiv},
  eprint = {1710.01688},
  eprinttype = {arxiv},
  file = {/home/joao/GDRIVE/Zotero/2017-dean_mania_matni_et_al-on_the_sample_complexity_of_the_linear_quadratic_regulator.pdf},
  keywords = {PT,PT1,R20_1,RL}
}

@article{fagiano2016a,
  title = {Learning a Nonlinear Controller from Data: {{Theory}}, Computation, and Experimental Results},
  author = {Fagiano, Lorenzo and Novara, Carlo},
  year = {2016},
  month = jul,
  volume = {61},
  pages = {1854--1868},
  issn = {00189286},
  doi = {10.1109/TAC.2015.2479520},
  abstract = {\textcopyright{} 2014 IEEE. In this paper, we consider the problem of learning a nonlinear controller directly from experimental data. We assume that an existing, unknown controller, able to stabilize the plant, is available, and that input-output measurements can be collected during closed loop operation. A theoretical analysis shows that the error between the input issued by the existing controller and the input given by the learned one shall have low variability in order to achieve closed loop stability. This result is exploited to derive a {$\mathscr{l}$}\textexclamdown inf\textquestiondown 1\textexclamdown/inf\textquestiondown -norm regularized learning algorithm that achieves the stability condition as the number of data points tends to infinity. The approach is completely based on convex optimization.},
  isbn = {9781467360883},
  journal = {IEEE Transactions on Automatic Control},
  keywords = {Airborne wind energy,data-driven control,dynamic inversion,identification for control,nonlinear control,PT,PT2},
  number = {7}
}

@inproceedings{formentin2011a,
  title = {Noniterative Data-Driven Design of Multivariable Controllers},
  booktitle = {2011 {{50TH IEEE CONFERENCE ON DECISION AND CONTROL AND EUROPEAN CONTROL CONFERENCE}} ({{CDC}}-{{ECC}})},
  author = {Formentin, Simone and Savaresi, Sergio M.},
  year = {2011},
  pages = {5106--5111},
  issn = {0743-1546},
  abstract = {In this paper, a data-driven technique is proposed to deal with multivariable fixed-order controller design. The method is based on the Virtual Reference Feedback Tuning (VRFT) philosophy and thus does not require any model of the plant. As far as the authors are aware, this is the first noniterative method that allows one to tune either tracking and decoupling terms of a MIMO controller. Unlike standard VRFT for SISO systems, extended instrumental variables and variance weighting are used to counteract the effect of noise and achieve consistent controller estimate with a single set of input-output data. The proposed strategy is validated on three banchmark examples.},
  isbn = {978-1-61284-801-3},
  keywords = {PT,PT2},
  series = {{{IEEE}} Conference on Decision and Control}
}

@article{formentin2013b,
  title = {Optimal Input Design for Direct Data-Driven Tuning of Model-Reference Controllers},
  author = {Formentin, Simone and Karimi, Alireza and Savaresi, Sergio M.},
  year = {2013},
  volume = {49},
  pages = {1874--1882},
  publisher = {{Elsevier Ltd}},
  issn = {00051098},
  doi = {10.1016/j.automatica.2013.02.054},
  abstract = {In recent years, direct data-driven controller tuning methods have been proposed as an alternative to the standard model-based approach for model-reference control design. In this work, the problem of input design for noniterative direct data-driven techniques, namely Virtual Reference Feedback Tuning (VRFT) and noniterative Correlation-based Tuning (CbT), is investigated. For bounded input energy, the excitation signal is designed such that the expected value of the considered control cost is reduced. The above strategy is numerically tested on a benchmark example. \textcopyright{} 2013 Elsevier Ltd. All rights reserved.},
  isbn = {9783902823069},
  journal = {Automatica},
  keywords = {CbT,Data-driven control,Identification for control,Input design,PT,PT2,VRFT},
  number = {6}
}

@article{formentin2015,
  title = {Nonparametric {{LPV}} Data-Driven Control},
  author = {Formentin, Simone and Piga, Dario and T{\'o}th, Roland and Savaresi, Sergio M.},
  year = {2015},
  volume = {48},
  pages = {146--151},
  publisher = {{Elsevier B.V.}},
  issn = {24058963},
  doi = {10.1016/j.ifacol.2015.11.128},
  abstract = {In this paper, a data-driven technique for linear parameter-varying (LPV) controller design is discussed. The proposed method allows to synthesize directly from data an LPV controller in input-output (IO) form, without the need to identifying a model of the plant. In the state of the art methods, the controller structure must be given a-priori. Instead, in the proposed approach both the controller structure and parameters are automatically determined based on a set of experimental measurements. The effectiveness of the method is demonstrated on a numerical example.},
  journal = {IFAC-PapersOnLine},
  keywords = {Data-driven control,Instrumental variables,LPV systems,LS-SVM,PT,PT2},
  number = {26}
}

@article{formentin2018a,
  title = {Robust Direct Data-Driven Controller Tuning with an Application to Vehicle Stability Control},
  author = {Formentin, S. and Garatti, S. and Rallo, G. and Savaresi, S. M.},
  year = {2018},
  volume = {28},
  pages = {3752--3765},
  issn = {10991239},
  doi = {10.1002/rnc.3782},
  abstract = {\textcopyright{} 2017 John Wiley \& Sons, Ltd. In direct data-driven controller tuning, a mathematical model of the plant is not needed, as the control law is directly derived from experimental data. Because the most widely used data-driven techniques are based on the assumption that the underlying dynamics - albeit unknow - is linear, the performance of the resulting controller may not be acceptable with systems whose operating region vary along the time. In this paper, we discuss how to robustify linear data-driven design by exploiting the features of scenario optimization. More specifically, we carry out a modified version of the well known virtual reference feedback tuning approach where probabilistic performance guarantees are given also when the current operating condition is different from the one observed in the controller identification experiment. We validate the proposed approach on a vehicle stability control problem, via a thorough simulation campaign on a multibody simulator. The experimental results show the effectiveness of the proposed approach in a complex real-world setting.},
  journal = {International Journal of Robust and Nonlinear Control},
  keywords = {data-driven control,PT,PT2,robust,vehicle stability,virtual reference feedback tuning},
  number = {12}
}

@article{guardabassi2000a,
  title = {Virtual Reference Direct Design Method: An off-Line Approach to Data-Based Control System Design},
  author = {Guardabassi, Guido O. and Savaresi, Sergio M.},
  year = {2000},
  volume = {45},
  pages = {954--959},
  issn = {00189286},
  doi = {10.1109/9.855559},
  abstract = {Abstract\textemdash This paper presents a direct model-reference approach to the off-line design of linear controllers, suited to deal with plants described by a single set of open-loop I/O measurements only. The method is direct inas- much as the controller parameters are directly estimated with no prelim- inary identification of any model to describe the plant. The design can be carried out off-line and, in the present formulation, leads to a nonadaptive controller. The basic idea is that of interpreting the open-loop I/O mea- surements of the plant as closed-loop data produced by a ``virtual'' refer- ence signal that can be computed by backpropagating the measured output of the plant through the reference model; thus, the controller design re- duces to a standard identification problem, in which the ``output'' signal to be matched is the measured input of the plant. Both a deterministic (noise-free) and a stochastic setting are considered. Index},
  journal = {IEEE Transactions on Automatic Control},
  keywords = {PT,PT2},
  number = {5}
}

@inproceedings{hedrea2016a,
  title = {Virtual Reference Feedback Tuning for Position Control of a Twin Rotor Aerodynamic System},
  booktitle = {2016 {{IEEE 11TH INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS}} ({{SACI}})},
  author = {Hedrea, Elena-Lorena and Radac, Mircea-Bogdan and Precup, Radu-Emil},
  year = {2016},
  pages = {57--62},
  abstract = {This paper presents a positioning control application of the Virtual Reference Feedback Tuning (VRFT) technique for linear feedback controllers of a Multi Input-Multi Output (MIMO) twin rotor aerodynamic system (TRAS). The VRFT technique is useful because it finds the parameters of linear feedback controllers without using the process model. The identified controller is validated both by a regression test for selecting the optimal number of parameters and by a whitening test on the prediction error. A set of experimental results for the pitch and azimuth MIMO control systems using both Singe Input-Single Output (SISO) controllers and MIMO ones demonstrate the VRFT theory. A comparison of several MIMO controllers' performance is given.},
  isbn = {978-1-5090-2380-6},
  keywords = {PT,PT2}
}

@techreport{hinton1984,
  title = {Distributed {{Representations}}},
  author = {Hinton, Geoffrey E},
  year = {1984},
  pages = {34},
  address = {{Pittsburgh, PA}},
  institution = {{Depart- ment of Computer Science, Carnegie-Mellon University}},
  abstract = {Given a \^network of simple computing elements and some entities to be represented, the most straightforward scheme is to use one computing element for each entity. This is called a local representation. It is easy to understand and easy to implement because the structure of the physical network mirrors the structure of the knowledge it contains. This report describes a different type of representation that is less familiar and harder to think about than local representations. Each entity is represented by a pattern of activity distributed over many computing elements, and each computing element is involved in representing many different entities. The strength of this more complicated kind of representation does not lie in its notational convenience or its ease of implementation in a conventional computer, but rather in the efficiency with which it makes use of the processing abilities of networks of simple, neuron-like computing elements.},
  file = {/home/joao/GDRIVE/Zotero/1984-hinton-distributed_representations.pdf},
  keywords = {PT,PT1},
  language = {en},
  number = {CMU-CS-84-157},
  type = {Technical {{Report}}}
}

@article{hjalmarsson1994,
  title = {A Convergent Iterative Restricted Complexity Control Design Scheme},
  author = {Hjalmarsson, H. and Gunnarsson, S. and Gevers, M.},
  year = {1994},
  volume = {2},
  pages = {1735--1740},
  issn = {01912216},
  doi = {10.1109/CDC.1994.411185},
  abstract = {In this contribution we propose an optimizationto the design of a restricted complexity. The design criterion is of LQG typetwo terms. The first term is the quadraticof the error between the output of the true closedand a desired response. The second term is thenorm of the input signal. It is shown thatminimization of this criterion does not require aof the system. Closed loop experimental data canused instead. The result is an iterative scheme ofloop experiments and controller updates whichto a local minimum of the design criterionthe condition of bounded signals},
  isbn = {0-7803-1968-0},
  journal = {Proceedings of 1994 33rd IEEE Conference on Decision and Control},
  keywords = {51 has sug-,a known plant,control design,criterion,edmunds,have explored the fact,however,in the case of,minimize a control design,no one seems to,optimization,PT,PT2,that,the objective is to},
  number = {December}
}

@phdthesis{hou1994,
  title = {The Parameter Identification, Adaptive Control and Model Free Learning Adaptive Control for Nonlinear Systems},
  author = {Hou, Zhong-Sheng},
  year = {1994},
  keywords = {PT,PT2},
  school = {Northeastern University},
  type = {{{PhD}} Dissertation}
}

@article{hou2011a,
  title = {A Novel Data-Driven Control Approach for a Class of Discrete-Time Nonlinear Systems},
  author = {Hou, Zhongsheng and Jin, Shangtai},
  year = {2011},
  month = nov,
  volume = {19},
  pages = {1549--1558},
  issn = {1063-6536},
  doi = {10.1109/TCST.2010.2093136},
  journal = {IEEE Transactions on Control Systems Technology},
  keywords = {PT,PT2},
  number = {6}
}

@article{hou2011b,
  title = {Data-Driven Model-Free Adaptive Control for a Class of {{MIMO}} Nonlinear Discrete-Time Systems},
  author = {Hou, Zhongsheng and Jin, Shangtai},
  year = {2011},
  volume = {22},
  pages = {2173--2188},
  issn = {10459227},
  doi = {10.1109/TNN.2011.2176141},
  abstract = {In this paper, a data-driven model-free adaptive control (MFAC) approach is proposed based on a new dynamic linearization technique (DLT) with a novel concept called pseudo-partial derivative for a class of general multiple-input and multiple-output nonlinear discrete-time systems. The DLT includes compact form dynamic linearization, partial form dynamic linearization, and full form dynamic linearization. The main feature of the approach is that the controller design depends only on the measured input/output data of the controlled plant. Analysis and extensive simulations have shown that MFAC guarantees the bounded-input bounded-output stability and the tracking error convergence.},
  isbn = {9781123478},
  journal = {IEEE Transactions on Neural Networks},
  keywords = {Compact form dynamic linearization,data-driven control,model-free adaptive control,multiple-input and multiple-output nonlinear syste,partial form dynamic linearization,pseudo-partial derivative,PT,PT2,stability},
  number = {12 PART 2},
  pmid = {22147302}
}

@article{hou2013,
  ids = {hou2013a,hou2013b},
  title = {From Model-Based Control to Data-Driven Control: {{Survey}}, Classification and Perspective},
  author = {Hou, Zhong Sheng and Wang, Zhuo},
  year = {2013},
  volume = {235},
  pages = {3--35},
  publisher = {{Elsevier Inc.}},
  issn = {00200255},
  doi = {10.1016/j.ins.2012.07.014},
  abstract = {This paper is a brief survey on the existing problems and challenges inherent in model-based control (MBC) theory, and some important issues in the analysis and design of data-driven control (DDC) methods are here reviewed and addressed. The necessity of data-driven control is discussed from the aspects of the history, the present, and the future of control theories and applications. The state of the art of the existing DDC methods and applications are presented with appropriate classifications and insights. The relationship between the MBC method and the DDC method, the differences among different DDC methods, and relevant topics in data-driven optimization and modeling are also highlighted. Finally, the perspective of DDC and associated research topics are briefly explored and discussed. \textcopyright{} 2012 Elsevier Inc. All rights reserved.},
  file = {/home/joao/GDRIVE/Zotero/2013-hou_wang-from_model-based_control_to_data-driven_control.pdf},
  isbn = {0020-0255},
  journal = {Information Sciences},
  keywords = {Data-based control,Data-driven control,DD,PT,PT2,Survey}
}

@article{hou2013a,
  title = {From Model-Based Control to Data-Driven Control: {{Survey}}, Classification and Perspective},
  author = {Hou, Zhong-Sheng and Wang, Zhuo},
  year = {2013},
  month = jun,
  volume = {235},
  pages = {3--35},
  issn = {00200255},
  doi = {10.1016/j.ins.2012.07.014},
  abstract = {This paper is a brief survey on the existing problems and challenges inherent in model-based control (MBC) theory, and some important issues in the analysis and design of data-driven control (DDC) methods are here reviewed and addressed. The necessity of data-driven control is discussed from the aspects of the history, the present, and the future of control theories and applications. The state of the art of the existing DDC methods and applications are presented with appropriate classifications and insights. The relationship between the MBC method and the DDC method, the differences among different DDC methods, and relevant topics in data-driven optimization and modeling are also highlighted. Finally, the perspective of DDC and associated research topics are briefly explored and discussed. \textcopyright{} 2012 Elsevier Inc. All rights reserved.},
  isbn = {0020-0255},
  journal = {Information Sciences},
  keywords = {Classification,Data-based control,Data-driven control,Perspective,PT,PT2,Survey}
}

@book{howard1960,
  title = {Dynamic {{Programming}} and {{Markov Processes}}},
  author = {Howard, R.},
  year = {1960},
  publisher = {{MIT Press}},
  address = {{Cambridge, MA}},
  keywords = {PT,PT1}
}

@incollection{huang2008,
  title = {Dynamic Modeling, Predictive Control and Performance Monitoring},
  booktitle = {Lecture Notes in Control and Information Sciences},
  author = {Huang, Biao and Kadali, Ramesh},
  year = {2008},
  pages = {249},
  issn = {01708643},
  doi = {10.1007/11597018_1},
  abstract = {The aim of this book is: 1) to provide an introduction to conventional system identification, model predictive control, and control performance monitoring, and 2) to present a novel subspace framework for closed-loop identification, datadriven predictive control and control performance monitoring. Dynamic modeling, control and monitoring are three central themes in systems and control. Under traditional design frameworks, dynamic models are the prerequisite of control and monitoring. However, models are only vehicles towards achieving these design objectives. Once the design of a controller or a monitor is completed, the model often ceases to exist. The use of models serves well for the design purpose as most traditional designs are model based; it also introduces unavoidable modeling error and complexity in building the model. If a model is identified from data, it is obvious that information contained in the model is no more than that within the original data. Can a controller or monitor be designed directly from input-output data bypassing the modeling step? This book aims to present novel subspace methods to address these questions. In addition, as necessary background material, this book also provides an introduction to the conventional system identification methods for both open-loop and closed-loop processes, conventional model predictive control design, conventional control loop performance assessment techniques, and state-of-the-art model predictive control performance monitoring algorithms. Thus, readers who are interested in conventional approaches to system identification, model predictive control, and control loop performance assessment will also find the book a useful tutorial-style reference.},
  isbn = {978-1-84800-232-6},
  keywords = {PT,PT2},
  pmid = {19886812}
}

@inproceedings{huissoon1995,
  title = {Data-Driven Control of Sonar Array Transducers},
  author = {Huissoon, J. P. and Purcell, D. W.},
  editor = {Foret, George D. and Lau, Kam C. and Nnaji, Bartholomew O.},
  year = {1995},
  month = dec,
  pages = {118--129},
  doi = {10.1117/12.228844},
  keywords = {airborne utrasound array transducer,beamforming,beamshaping,PT,PT2},
  number = {December 1995}
}

@article{huusom2009,
  title = {Improving Convergence of Iterative Feedback Tuning},
  author = {Huusom, Jakob Kj{\o}bsted and Poulsen, Niels Kj{\o}lstad and J{\o}rgensen, Sten Bay},
  year = {2009},
  month = apr,
  volume = {19},
  pages = {570--578},
  issn = {09591524},
  doi = {10.1016/j.jprocont.2008.09.004},
  abstract = {Iterative Feedback Tuning constitutes an attractive control loop tuning method for processes in the absence of an accurate process model. It is a purely data driven approach aiming at optimizing the closed loop performance. The standard formulation ensures an unbiased estimate of the loop performance cost function gradient with respect to the control parameters. This gradient is important in a search algorithm. The extension presented in this paper further ensures informative data to improve the convergence properties of the method and hence reduce the total number of required plant experiments especially when tuning for disturbance rejection. Informative data is achieved through application of an external probing signal in the tuning algorithm. The probing signal is designed based on a constrained optimization which utilizes an approximate black box model of the process. This model estimate is further used to guarantee nominal stability and to improve the parameter update using a line search algorithm for determining the iteration step size. The proposed algorithm is compared to the classical formulation in a simulation study of a disturbance rejection problem. This type of problem is notoriously difficult for Iterative Feedback Tuning due to the lack of excitation from the reference. \textcopyright{} 2008 Elsevier Ltd. All rights reserved.},
  isbn = {9781424431243},
  journal = {Journal of Process Control},
  keywords = {Controller tuning,Experimental design,Iterative Feedback Tuning,PT,PT2},
  number = {4}
}

@inproceedings{ikeda2001,
  title = {A Model-Less Algorithm for Tracking Control Based on Input-Output Data},
  booktitle = {Nonlinear Analysis, Theory, Methods and Applications},
  author = {Ikeda, Masao and Fujisaki, Yasumasa and Hayashi, Naoki},
  year = {2001},
  volume = {47},
  pages = {1953--1960},
  issn = {0362546X},
  doi = {10.1016/S0362-546X(01)00324-8},
  abstract = {This paper proposes an idea of data-driven predictive control for a linear discrete-time system, that is, a tracking control algorithm based on input-output data. Any traditional model of the plant, such as a transfer function or a state equation, is not employed. The plant dynamics is represented by a rank constraint in an array whose elements are input-output data. The control input for tracking an arbitrary reference signal is readily computed using linear dependence of rows in the array. By refreshing the data, the algorithm can adapt to the change of the plant dynamics.},
  keywords = {PT,PT2}
}

@inproceedings{ISI:000427123500187,
  title = {Multi Input-Multi Output Tank System Data-Driven Model Reference Control},
  booktitle = {2017 {{13TH IEEE INTERNATIONAL CONFERENCE ON CONTROL}} \& {{AUTOMATION}} ({{ICCA}})},
  author = {Radac, Mircea-Bogdan and Precup, Radu-Emil and Roman, Raul-Cristian},
  year = {2017},
  pages = {1078--1083},
  issn = {1948-3449},
  abstract = {This paper suggests a model-free control approach for tuning nonlinear state feedback controllers to ensure model reference output tracking in an optimal control framework. An iterative Batch fitted Q (BFQ)-learning strategy uses two neural networks (NNs) to estimate the value function (critic) and the controller (actor). An initially stabilizing linear Virtual Reference Feedback Tuning (VRFT) controller learned from few input-output process samples is then used to collect significantly more input-state-output samples in a controlled constrained environment, by compensating for undesired process dynamics. This collected data is subsequently used to learn significantly superior nonlinear state feedback NN controllers for model reference output tracking using the proposed iterative BFQ-learning strategy. The mixed VRFT-BFQ learning approach is experimentally validated on the water level control of a multi input-multi output (MIMO) nonlinear constrained coupled two-tank system. Although the VRFT control is designed independently for each control channel and does not ensure decoupling, straightforward (MIMO) BFQ-learning proves good decoupling and ensures indirect linearization of the feedback MIMO control system.},
  isbn = {978-1-5386-2679-5},
  keywords = {PT,PT2},
  series = {{{IEEE}} International Conference on Control and Automation {{ICCA}}}
}

@incollection{jeng2014a,
  title = {Controller Design for Nonlinear Hammerstein and Wiener Systems Based on {{VRFT}} Method},
  booktitle = {Computer Aided Chemical Engineering},
  author = {Jeng, Jyh-Cheng and Lin, Yi-Wei},
  year = {2014},
  volume = {33},
  pages = {547--552},
  issn = {15707946},
  doi = {10.1016/B978-0-444-63456-6.50092-2},
  abstract = {This paper presents a novel data-based controller design for nonlinear Hammerstein and Wiener systems based on the VRFT design framework. In the proposed method, identification of a complete dynamic model of the nonlinear system is not required, whereas only the static nonlinearity has to be estimated. Furthermore, the nonlinearity estimation and the controller design are performed simultaneously without the needs of iterative procedures or nonlinear optimization. Simulation study of a pH neutralization process confirms the effectiveness of the proposed controller design method. \textcopyright{} 2014 Elsevier B.V.},
  keywords = {Hammerstein system,Nonlinear process control,PT,PT2,VRFT,Wiener system}
}

@inproceedings{jeng2015a,
  title = {Extended {{VRFT}} Method for Controller Design of Nonlinear Systems Based on Block-Oriented Model Structures},
  booktitle = {Computer Aided Chemical Engineering},
  author = {Jeng, Jyh-Cheng and Lin, Yi-Wei and Lee, Min-Wei},
  editor = {R, Gernaey KV and JK, Huusom and {Gani}},
  year = {2015},
  volume = {37},
  pages = {1691--1696},
  issn = {15707946},
  doi = {10.1016/B978-0-444-63577-8.50127-3},
  abstract = {This paper presents a novel data-based controller design for nonlinear systems based on the VRFT design framework and block-oriented modeling. Identification of a complete dynamic model of the nonlinear system is not required, whereas only the static nonlinearity has to be estimated. Moreover, the nonlinearity estimation and the controller design are performed simultaneously without the needs of iterative procedures or nonlinear optimization. Simulation studies of a distillation column and a pH neutralization process confirms the effectiveness of the proposed design method.},
  isbn = {978-0-444-63577-8},
  keywords = {Hammerstein system,Nonlinear process control,PT,PT2,VRFT,Wiener system},
  series = {Computer Aided Process Engineering}
}

@article{jeng2018a,
  title = {Data-Driven Nonlinear Control Design Using Virtual-Reference Feedback Tuning Based on the Block-Oriented Modeling of Nonlinear Systems},
  author = {Jeng, Jyh-Cheng and Lin, Yi-Wei},
  year = {2018},
  month = jun,
  volume = {57},
  pages = {7583--7599},
  issn = {0888-5885},
  doi = {10.1021/acs.iecr.8b00809},
  journal = {Industrial \& Engineering Chemistry Research},
  keywords = {PT,PT2},
  number = {22}
}

@article{kalman1960,
  title = {A New Approach to Linear Filtering and Prediction Problems},
  author = {Kalman, R E},
  year = {1960},
  month = mar,
  volume = {82},
  pages = {35--45},
  publisher = {{ASME}},
  issn = {0098-2202},
  abstract = {The classical filtering and prediction problem is re-examined using the Bode-Shannon representation of random processes and the ``state-transition'' method of analysis of dynamic systems. New results are: (1) The formulation and methods of solution of the problem apply without modification to stationary and nonstationary statistics and to growing-memory and infinite-memory filters. (2) A nonlinear difference (or differential) equation is derived for the covariance matrix of the optimal estimation error. From the solution of this equation the co-efficients of the difference (or differential) equation of the optimal linear filter are obtained without further calculations. (3) The filtering problem is shown to be the dual of the noise-free regulator problem. The new method developed here is applied to two well-known problems, confirming and extending earlier results. The discussion is largely self-contained and proceeds from first principles; basic concepts of the theory of random processes are reviewed in the Appendix.},
  journal = {Journal of Basic Engineering},
  keywords = {PT,PT2},
  number = {1}
}

@inproceedings{kammer2000,
  title = {Direct Iterative Tuning via Spectral Analysis},
  booktitle = {Proceedings of the 37th {{IEEE}} Conference on Decision and Control (Cat. {{No}}.{{98CH36171}})},
  author = {Kammer, L.C. and Bitmead, R.R. and Bartlett, P.L.},
  year = {2000},
  volume = {3},
  pages = {2874--2879},
  publisher = {{IEEE}},
  issn = {00051098},
  doi = {10.1109/CDC.1998.757912},
  abstract = {This paper introduces a nonparametric frequency-domain scheme for tuning closed-loop systems. A linear quadratic criterion is used for guiding the system towards an optimal-regulation state. The computation of tuning directions is performed with unbiased estimates of first and second derivatives of the cost function. In order to provide cautious adjustments of the controller parameters, this scheme introduces a mechanism that guarantees stability of the loop during the tuning procedure. This mechanism uses the generalized stability margin and a metric on transfer functions to impose safe limits on the variation of the control law.},
  isbn = {0-7803-4394-8},
  keywords = {control tuning,iterative de-,optimisation,PT,PT2}
}

@article{karimi2002,
  title = {Convergence Analysis of an Iterative Correlation-Based Controller Tuning Method},
  author = {Karimi, A. and Mi{\v s}kovi{\'c}, L. and Bonvin, D.},
  year = {2002},
  volume = {35},
  pages = {413--418},
  issn = {14746670},
  doi = {10.3182/20020721-6-ES-1901.00150},
  journal = {IFAC Proceedings Volumes (IFAC-PapersOnline)},
  keywords = {Controller tuning,Convergence analysis,Instrumental variables,PT,PT2},
  number = {1}
}

@inproceedings{karimi2007,
  title = {Non-Iterative Data-Driven Controller Tuning Using the Correlation Approach},
  booktitle = {2007 European Control Conference ({{ECC}})},
  author = {Karimi, Alireza and {van Heusden}, Klaske and Bonvin, Dominique},
  year = {2007},
  month = jul,
  volume = {3536},
  pages = {5189--5195},
  publisher = {{IEEE}},
  doi = {10.23919/ECC.2007.7068802},
  isbn = {978-3-9524173-8-6},
  keywords = {PT,PT2}
}

@inproceedings{konidaris2011,
  title = {Value Function Approximation in Reinforcement Learning Using the Fourier Basis},
  booktitle = {Proceedings of the {{Twenty}}-{{Fifth AAAI Conference}} on {{Artificial Intelligence}}},
  author = {Konidaris, George and Osentoski, Sarah and Thomas, Philip},
  year = {2011},
  pages = {380--385},
  publisher = {{AAAI Press}},
  address = {{San Francisco, California}},
  abstract = {We describe the Fourier basis, a linear value function approximation scheme based on the Fourier series. We empirically demonstrate that it performs well compared to radial basis functions and the polynomial basis, the two most popular fixed bases for linear value function approximation, and is competitive with learned proto-value functions.},
  file = {/home/joao/GDRIVE/Zotero/2011-konidaris_osentoski_thomas-value_function_approximation_in_reinforcement_learning_using_the_fourier_basis.pdf},
  keywords = {PT,PT1},
  series = {{{AAAI}}'11}
}

@article{lewis2012,
  ids = {2012},
  title = {Reinforcement Learning and Feedback Control: {{Using}} Natural Decision Methods to Design Optimal Adaptive Controllers},
  author = {Lewis, Frank L. and Vrabie, Draguna and Vamvoudakis, Kyriakos G.},
  year = {2012},
  volume = {32},
  pages = {76--105},
  publisher = {{IEEE}},
  issn = {1066033X},
  doi = {10.1109/MCS.2012.2214134},
  abstract = {This article describes the use of principles of reinforcement learning to design feedback controllers for discrete- and continuous-time dynamical systems that combine features of adaptive control and optimal control. Adaptive control [1], [2] and optimal control [3] represent different philosophies for designing feedback controllers. Optimal controllers are normally designed of ine by solving Hamilton JacobiBellman (HJB) equations, for example, the Riccati equation, using complete knowledge of the system dynamics. Determining optimal control policies for nonlinear systems requires the offline solution of nonlinear HJB equations, which are often difficult or impossible to solve. By contrast, adaptive controllers learn online to control unknown systems using data measured in real time along the system trajectories. Adaptive controllers are not usually designed to be optimal in the sense of minimizing user-prescribed performance functions. Indirect adaptive controllers use system identification techniques to first identify the system parameters and then use the obtained model to solve optimal design equations [1]. Adaptive controllers may satisfy certain inverse optimality conditions [4].},
  annotation = {ZSCC: 0000511},
  file = {/home/joao/GDRIVE/Zotero/2012-lewis_vrabie_vamvoudakis-reinforcement_learning_and_feedback_control.pdf},
  journal = {IEEE Control Systems},
  keywords = {actor-critic,DD,PT,PT1,R20_1,RL},
  number = {6}
}

@inproceedings{liu2019,
  title = {Attitude {{Synchronization}} for {{Multiple Quadrotors}} Using {{Reinforcement Learning}}*},
  booktitle = {2019 {{Chinese Control Conference}} ({{CCC}})},
  author = {Liu, Hao and Zhao, Wanbing and Lewis, Frank L. and Jiang, Zhong-Ping and Modares, Hamidreza},
  year = {2019},
  month = jul,
  pages = {2480--2483},
  issn = {1934-1768},
  doi = {10/gg5nkr},
  abstract = {In this paper, a reinforcement learning based control law is proposed to solve the attitude synchronization problem of the leader-following multi-quadrotor systems. The overall system is composed of a team of quadrotors, modeled with highly nonlinear and coupled dynamics. An optimal control solution is obtained by solving an augmented Hamilton-Jacobi-Bellman equation. A reinforcement learning approach is used to learn the optimal control law. Simulation results are provided to verify the effectiveness of the proposed controller.},
  annotation = {ZSCC: 0000000},
  file = {/home/joao/GDRIVE/Zotero/2019-liu_zhao_lewis_et_al-attitude_synchronization_for_multiple_quadrotors_using_reinforcement_learning.pdf;/home/joao/DADOS/GDRIVE/Zoterocfg/storage/JSEPW3VM/8865177.html},
  keywords = {aircraft control,attitude control,Attitude control,attitude synchronization problem,augmented Hamilton-Jacobi-Bellman equation,control engineering computing,control system synthesis,helicopters,highly nonlinear coupled dynamics,leader-following multiquadrotor systems,learning (artificial intelligence),Mathematical model,multiple quadrotors,nonlinear control systems,Nonlinear dynamical systems,Observers,optimal control,Optimal control,optimal control law,optimal control solution,PT,PT1,Reinforcement learning,reinforcement learning approach,reinforcement learning based control law,RL,stochastic processes,synchronisation,Synchronization}
}

@book{ljung1999,
  title = {System Identification: {{Theory}} for the User},
  author = {Ljung, Lennart},
  year = {1999},
  pages = {609},
  publisher = {{Prentice Hall}},
  address = {{New Jersey, US}},
  isbn = {978-0-13-656695-3},
  keywords = {PT,PT2}
}

@article{madadi2018a,
  title = {Model-Free Control of Unknown Nonlinear Systems Using an Iterative Learning Concept: Theoretical Development and Experimental Validation},
  author = {Madadi, Elmira and S{\"o}ffker, Dirk},
  year = {2018},
  volume = {94},
  pages = {1--13},
  publisher = {{Springer Netherlands}},
  issn = {1573269X},
  doi = {10.1007/s11071-018-4415-7},
  isbn = {1107101844157},
  journal = {Nonlinear Dynamics},
  keywords = {Adaptive iterative learning control,Model-free control approach,PT,PT2,Unknown nonlinear dynamical system},
  number = {2}
}

@phdthesis{martins2016,
  title = {Modelos {{Autorregressivos}} Para Representa\c{c}\~ao de Sistemas Com Histerese},
  author = {Martins, Samir Angelo Milani},
  year = {2016},
  pages = {104},
  keywords = {PT,PT2},
  school = {UFMG},
  type = {Tese de Doutorado}
}

@article{maupong2017,
  title = {Data-Driven Control: {{A}} Behavioral Approach},
  author = {Maupong, T. M. and Rapisarda, P.},
  year = {2017},
  volume = {101},
  pages = {37--43},
  publisher = {{Elsevier B.V.}},
  issn = {01676911},
  doi = {10.1016/j.sysconle.2016.04.006},
  abstract = {In this work, we study the design of a controller using system data. We present three data-driven approaches based on the notion of control as interconnection. In the first approach, we use both the data and representations to compute control variable trajectories that impose a prescribed path on the to-be-controlled variables. The second method is completely data-driven and we prove sufficient conditions for determining a controller directly from data. Finally, we show how to determine a controller directly from data in the case where the control and to-be-controlled variables coincide.},
  journal = {Systems and Control Letters},
  keywords = {Annihilators,Behavioral approach,Data-driven control,Interconnection,PT,PT2}
}

@article{maxwell1868,
  title = {On Governors},
  author = {Maxwell, J C},
  year = {1868},
  volume = {16},
  pages = {270--283},
  journal = {Proc. Roy. Soc.},
  keywords = {PT,PT2}
}

@article{novara2012,
  title = {Direct Feedback Control Control Design for Nonlinear Systems},
  author = {Novara, C. and Fagiano, L. and Milanese, M.},
  year = {2012},
  volume = {49},
  pages = {2140--2145},
  issn = {01912216},
  doi = {10.1109/CDC.2012.6426500},
  abstract = {We propose an approach for the direct design from data of controllers finalized at solving tracking problems for nonlinear systems. This approach, called Direct FeedbacK (DFK) design, overcomes relevant problems typical of the standard design methods, such as modeling errors, non-trivial parameter identification, non-convex optimization, and difficulty in nonlinear control design. Considering a Set Membership (SM) setting, we provide two main contributions. The first one is a theoretical framework for the stability analysis of nonlinear feedback control systems, in which the controller {\^f} is an approximation identified from data of an ideal inverse model f o. In this framework, we derive sufficient conditions under which {\^f} stabilizes the closed-loop system. The second contribution is a technique for the direct design of an approximate controller f* from data, having suitable optimality and sparsity properties. In particular, we show that f* is an almost-optimal controller (in a worst-case sense), and we derive a guaranteed accuracy bound, which can be used to quantify the performance level of the DFK control system. The technique is based on convex optimization and sparse identification methods, and thus avoids the problem of local minima and allows an efficient on-line controller implementation in real-world applications. \textcopyright{} 2012 IEEE.},
  isbn = {978-1-4673-2066-5},
  journal = {Proceedings of the IEEE Conference on Decision and Control},
  keywords = {Direct control design from data,Dynamic inversion,Nonlinear systems,PT,PT2,Stability},
  number = {4}
}

@article{novara2014,
  title = {Control of Nonlinear Systems: A Model Inversion Approach},
  author = {Novara, C. and Milanese, M.},
  year = {2014},
  pages = {1--4},
  abstract = {A novel control design approach for general nonlinear systems is presented in this paper. The approach is based on the identification of a polynomial model of the system to control and on the on-line inversion of this model. An efficient technique is developed to perform the inversion, which allows an effective control implementation on real-time processors.},
  archivePrefix = {arXiv},
  arxivid = {1407.1069},
  eprint = {1407.1069},
  eprinttype = {arxiv},
  journal = {arXiv},
  keywords = {PT,PT2},
  number = {1}
}

@article{novara2014a,
  title = {Data-Driven Controller Design for Nonlinear Systems: A Two Degrees of Freedom Architecture},
  author = {Novara, Carlo and Formentin, Simone},
  year = {2014},
  month = jul,
  pages = {1--5},
  abstract = {In this paper, the D2-IBC (Data-Driven Inversion Based Control) approach for nonlinear control is introduced and analyzed. The method does not require any a-priori knowledge of the system dynamics and relies on a two degrees of freedom scheme, with a nonlinear controller and a linear controller running in parallel. In particular, the former is devoted to stabilize the system around a trajectory of interest, whereas the latter is used to boost the closed-loop performance. The paper also presents a thorough stability and performance analysis of the closed-loop system.},
  archivePrefix = {arXiv},
  arxivid = {1407.2068},
  eprint = {1407.2068},
  eprinttype = {arxiv},
  journal = {arXiv},
  keywords = {PT,PT2}
}

@article{novara2015,
  title = {A Data-Driven Approach to Nonlinear Braking Control},
  author = {Novara, Carlo and Formentin, Simone and Savaresi, Sergio M. and Milanese, Mario},
  year = {2015},
  volume = {54rd IEEE},
  pages = {1453--1458},
  issn = {07431546},
  doi = {10.1109/CDC.2015.7402415},
  abstract = {? 2015 IEEE.In modern road vehicles, active braking control systems are crucial elements to ensure safety and lateral stability. Unfortunately, the wheel slip dynamics is highly nonlinear and the on-line estimation of the road-tire conditions is still a challenging open research problem. These facts make it difficult to devise a braking control system that is reliable in any situation without being too conservative. In this paper, we propose the Data-Driven Inversion Based Control (D2-IBC) approach to overcome the above issues. The method relies on a two degrees of freedom architecture, with a linear controller and a nonlinear controller in parallel, both designed using only experimental data. The effectiveness of the proposed approach is shown by means of an extensive simulation campaign.},
  isbn = {9781479978861},
  journal = {Proceedings of the IEEE Conference on Decision and Control},
  keywords = {PT,PT2},
  number = {October}
}

@article{novara2016b,
  title = {Data-Driven Design of Two Degree-of-Freedom Nonlinear Controllers: {{The D}}{$^2$}-{{IBC}} Approach},
  author = {Novara, Carlo and Formentin, Simone and Savaresi, Sergio M. and Milanese, Mario},
  year = {2016},
  volume = {72},
  pages = {19--27},
  publisher = {{Elsevier Ltd}},
  issn = {00051098},
  doi = {10.1016/j.automatica.2016.05.010},
  abstract = {In this paper, we introduce and discuss the Data-Driven Inversion-Based Control (D2-IBC) method for nonlinear control system design. The method relies on a two degree-of-freedom architecture, with a nonlinear controller and a linear controller running in parallel, and does not require any detailed physical knowledge of the plant to control. Specifically, we use input/output data to synthesize the controller by employing convex optimization tools. We show the effectiveness of the proposed approach on a benchmark simulation example, regarding control of the Duffing system.},
  journal = {Automatica},
  keywords = {Closed-loop stability,Data-driven control design,Nonlinear systems,PT,PT2}
}

@inproceedings{novara2016c,
  title = {A Data-Driven Model Inversion Approach to Cancer Immunotherapy Control},
  booktitle = {2016 {{IEEE 55TH CONFERENCE ON DECISION AND CONTROL}} ({{CDC}})},
  author = {Novara, Carlo and Karimshoushtari, Milad},
  year = {2016},
  pages = {5047--5052},
  issn = {0743-1546},
  abstract = {A novel data-driven control design approach for Multiple Input Multiple Output nonlinear systems is proposed in the paper, relying on the identification of a polynomial prediction model of the system to control and its on-line inversion. A simulated study is then presented, concerning the design of a control strategy for cancer immunotherapy. This study shows that the proposed approach may be quite effective in treating cancer patients, and may give results similar to (or perhaps better than) those provided by ``standard'' methods. The fundamental difference is that ``standard'' methods are typically based on the unrealistic assumption that an accurate physiological model of the cancer-immune mechanism is available; in the approach proposed here, the controller is designed without such a strong assumption.},
  isbn = {978-1-5090-1837-6},
  keywords = {PT,PT2},
  series = {{{IEEE}} Conference on Decision and Control}
}

@article{novara2018,
  title = {Data-Driven Inversion-Based Control of Nonlinear Systems with Guaranteed Closed-Loop Stability},
  author = {Novara, Carlo and Formentin, Simone},
  year = {2018},
  volume = {63},
  pages = {1147--1154},
  issn = {00189286},
  doi = {10.1109/TAC.2017.2744499},
  abstract = {\textemdash The Data-Driven Inversion-Based Control (D 2 -IBC) approach is a recently introduced control design method for uncertain nonlinear systems, relying on a two degree-of-freedom architecture, with a nonlinear controller and a linear controller running in parallel. Unlike other approaches for nonlinear control, D 2 -IBC does not require an accurate modeling of the plant and is computationally efficient. In this note, we introduce a finite-gain stability sufficient condition for the closed-loop system and prove that such a condition theoretically holds when a suitable constraint is enforced during the controller design. Finally, we compare the original and the modified methods on a benchmark simulation example, regarding control of the Duffing oscillator.},
  journal = {IEEE Transactions on Automatic Control},
  keywords = {closed-loop stability,Data-driven control design,nonlinear systems,PT,PT2},
  number = {4}
}

@article{nowak2016a,
  title = {Data-Driven Stabilization of Unknown Nonlinear Dynamical Systems Using a Cognition-Based Framework},
  author = {Nowak, Xi and S{\"o}ffker, Dirk},
  year = {2016},
  volume = {86},
  pages = {1--15},
  issn = {1573269X},
  doi = {10.1007/s11071-016-2868-0},
  abstract = {\textcopyright{} 2016, Springer Science+Business Media Dordrecht. In this paper, a cognitive stabilizer concept is introduced. The framework acts as an adaptive discrete control approach. The aim of the cognitive stabilizer is to stabilize a specific class of unknown nonlinear MIMO systems. The cognitive stabilizer is able to gain useful local knowledge of the system assumed as unknown. The approach is able to define autonomously suitable control inputs to stabilize the system. The system class to be considered is described by the following assumptions: unknown input/output behavior, fully controllable, stable zero dynamics, and measured state vector. The cognitive stabilizer is realized by its four main modules: (1) ``perception and interpretation'' using system identifier for the system local dynamic online identification and multi-step-ahead prediction; (2) ``expert knowledge'' relating to the quadratic stability criterion to guarantee the stability of the considered motion of the controlled system; (3) ``planning'' to generate a suitable control input sequence according to a certain cost function; (4) ``execution'' to generate the optimal control input in a corresponding feedback form. Each module can be realized using different methods. Two realizations will be stated in this paper. Using the cognitive stabilizer, the control goal can be achieved efficiently without an individual control design process for different kinds of unknown systems. Numerical examples (e.g., a chaotic nonlinear MIMO system\textendash Lorenz system) demonstrate the successful application of the proposed methods.},
  journal = {Nonlinear Dynamics},
  keywords = {Adaptive stabilizer,Cognitive,Data-driven approach,High autonomy,PT,PT2,Unknown nonlinear dynamical MIMO system},
  number = {1}
}

@article{nyquist1932,
  title = {Regeneration Theory},
  author = {Nyquist, H.},
  year = {1932},
  volume = {11},
  pages = {126--147},
  issn = {00058580},
  doi = {10.1002/j.1538-7305.1932.tb02344.x},
  abstract = {Regeneration or feeback is of considerable importance in many applications of vacuum tubes. The most obvious example is that of vacuum tube oscillators, where the feed-back is carried beyond the singing point. Another application is the 21-circuit test of balance, in which the current due to the unbalance between two impedances is fed back, the gain being increased until singing occurs. Still other applications are cases where portions of the output current of amplifiers are fed back to the input either unintentionally or by design. For the purpose of investigating the stability of such devices they may be looked on as amplifiers whose output is connected to the input through a transducer. This paper deals with the theory of stability of such systems.},
  isbn = {499226197},
  journal = {Bell System Technical Journal},
  keywords = {PT,PT2},
  number = {1}
}

@book{ogata2010,
  title = {Modern Control Engineering},
  author = {Ogata, Katsuhiko.},
  year = {2010},
  publisher = {{Prentice-Hall}},
  abstract = {5th ed. Introduction to control systems -- Mathematical modeling of control systems -- Mathematical modeling of mechanical systems and electrical systems -- Mathematical modeling of fluid systems and thermal systems -- Transient and steady-state response analyses -- Control systems analysis and design by the root-locus method -- Control systems analysis and design by the frequency-response method -- PID controllers and modified PID controllers -- Control systems analysis in state space -- Control systems design in state space -- Appendix A : Laplace transform tables -- Appendix B : Partial-fraction expansion -- Appendix C : Vector-matrix algebra.},
  keywords = {\#nosource,Controle,PT,PT1,Teoria de Controle}
}

@incollection{powell1987,
  title = {Radial Basis Functions for Multivariable Interpolation: A Review},
  shorttitle = {Radial Basis Functions for Multivariable Interpolation},
  booktitle = {Algorithms for Approximation},
  author = {Powell, M. J. D.},
  year = {1987},
  pages = {143--167},
  publisher = {{Clarendon Press}},
  address = {{USA}},
  isbn = {978-0-19-853612-3},
  keywords = {PT,PT1}
}

@article{previdi2004a,
  title = {Data-Driven Control Design for Neuroprotheses: {{A}} Virtual Reference Feedback Tuning ({{VRFT}}) Approach},
  author = {Previdi, Fabio and Schauer, Thomas and Savaresi, Sergio M. and Hunt, Ken J.},
  year = {2004},
  volume = {12},
  pages = {176--182},
  issn = {10636536},
  doi = {10.1109/TCST.2003.821967},
  abstract = {This paper deals with design of feedback controllers for knee joint movement of paraplegics using functional electrical stimulation (FES) of the paralyzed quadriceps muscle group. The controller design approach, virtual reference feedback tuning (VRFT), is directly based on open loop measured data and fits the controller in such a way that the closed-loop meets a model reference objective. The use of this strategy, avoiding the modeling step, significantly reduces the time required for controller design and considerably simplifies the rehabilitation protocols. Linear and nonlinear controllers have been designed and experimentally tested, preliminarily on a healthy subject and finally on a paraplegic patient. Linear controller is effective when applied on small range of knee joint angle. The design of a nonlinear controller allows better performances. It is also shown that the control design is effective in tracking assigned knee angle trajectories and rejecting disturbances.},
  journal = {IEEE Transactions on Control Systems Technology},
  keywords = {Direct controller design,Functional electrical stimulation (FES),Neuroprostheses,PT,PT2,Virtual reference feedback tuning (VRFT)},
  number = {1}
}

@article{radac2018b,
  title = {Data-Driven Model Reference Control of {{MIMO}} Vertical Tank Systems with Model-Free {{VRFT}} and {{Q}}-{{Learning}}},
  author = {Radac, Mircea Bogdan and Precup, Radu Emil and Roman, Raul Cristian},
  year = {2018},
  volume = {73},
  pages = {22--30},
  issn = {00190578},
  doi = {10.1016/j.isatra.2018.01.014},
  abstract = {This paper proposes a combined Virtual Reference Feedback Tuning\textendash Q-learning model-free control approach, which tunes nonlinear static state feedback controllers to achieve output model reference tracking in an optimal control framework. The novel iterative Batch Fitted Q-learning strategy uses two neural networks to represent the value function (critic) and the controller (actor), and it is referred to as a mixed Virtual Reference Feedback Tuning\textendash Batch Fitted Q-learning approach. Learning convergence of the Q-learning schemes generally depends, among other settings, on the efficient exploration of the state-action space. Handcrafting test signals for efficient exploration is difficult even for input-output stable unknown processes. Virtual Reference Feedback Tuning can ensure an initial stabilizing controller to be learned from few input-output data and it can be next used to collect substantially more input-state data in a controlled mode, in a constrained environment, by compensating the process dynamics. This data is used to learn significantly superior nonlinear state feedback neural networks controllers for model reference tracking, using the proposed Batch Fitted Q-learning iterative tuning strategy, motivating the original combination of the two techniques. The mixed Virtual Reference Feedback Tuning\textendash Batch Fitted Q-learning approach is experimentally validated for water level control of a multi input-multi output nonlinear constrained coupled two-tank system. Discussions on the observed control behavior are offered.},
  journal = {ISA Transactions},
  keywords = {Batch fitted Q-learning,Model reference tracking,Model-free optimal control,Multi input-multi output systems,Neural networks,PT,PT2,Vertical tank systems,Virtual reference feedback tuning}
}

@inproceedings{rallo2016a,
  title = {Vehicle Stability Control via {{VRFT}} with Probabilistic Robustness Guarantees},
  booktitle = {2016 {{IEEE}} 55th Conference on Decision and Control, {{CDC}} 2016},
  author = {Rallo, Gianmarco and Formentin, Simone and Garatti, Simone and Savaresi, Sergio M.},
  year = {2016},
  pages = {7165--7170},
  doi = {10.1109/CDC.2016.7799374},
  abstract = {\textcopyright{} 2016 IEEE. In four-wheel steering vehicles, the rear wheels can be used to adjust the driver's front action to enhance vehicle stability and performance. To the best of the authors' knowledge, all the existing control design methods rely on a simple model of the lateral dynamics, which may lead to unsatisfactory results in case of uncertainty. In this paper, we propose to use a modified version of the (model-free) Virtual Reference Feedback Tuning approach, where probabilistic guarantees are given for operating conditions different from the identification experiment. We validate the proposed approach on a thorough simulation campaign using a multibody simulator.},
  isbn = {978-1-5090-1837-6},
  keywords = {PT,PT2}
}

@article{rallo2017a,
  title = {Virtual Reference Feedback Tuning with {{Bayesian}} Regularization},
  author = {Rallo, Gianmarco and Formentin, Simone and Chiuso, Alessandro and Savaresi, Sergio M.},
  year = {2017},
  pages = {507--512},
  doi = {10.1109/ECC.2016.7810335},
  abstract = {Virtual Reference Feedback Tuning (VRFT) is a well established tool to design model-reference controllers directly from input-output data. A major drawback of the method lies in that the variance of the controller is high, due to the instrumental variable method employed to obtain unbiased estimates. Recent results on the use of kernel-based regularization in system identification showed that a good bias-variance trade-off can be found by suitably tuning a penalty term in the identification criterion within a Bayesian frame-work. In this paper, we apply such a regularization approach to the VRFT method and we show that significant performance improvement can be obtained also for controller design. A benchmark example is used to illustrate the effectiveness of the proposed approach.},
  isbn = {9781509025916},
  journal = {2016 European Control Conference, ECC 2016},
  keywords = {PT,PT2}
}

@article{recht2019,
  ids = {recht2018},
  title = {A {{Tour}} of {{Reinforcement Learning}}: {{The View}} from {{Continuous Control}}},
  shorttitle = {A {{Tour}} of {{Reinforcement Learning}}},
  author = {Recht, Benjamin},
  year = {2019},
  month = may,
  volume = {2},
  pages = {253--279},
  issn = {2573-5144, 2573-5144},
  doi = {10.1146/annurev-control-053018-023825},
  abstract = {This article surveys reinforcement learning from the perspective of optimization and control, with a focus on continuous control applications. It reviews the general formulation, terminology, and typical experimental implementations of reinforcement learning as well as competing solution paradigms. In order to compare the relative merits of various techniques, it presents a case study of the linear quadratic regulator (LQR) with unknown dynamics, perhaps the simplest and best-studied problem in optimal control. It also describes how merging techniques from learning theory and control can provide nonasymptotic characterizations of LQR performance and shows that these characterizations tend to match experimental behavior. In turn, when revisiting more complex applications, many of the observed phenomena in LQR persist. In particular, theory and experiment demonstrate the role and importance of models and the cost of generality in reinforcement learning algorithms. The article concludes with a discussion of some of the challenges in designing learning systems that safely and reliably interact with complex and uncertain environments and how tools from reinforcement learning and control might be combined to approach these challenges.},
  annotation = {ZSCC: 0000147},
  archivePrefix = {arXiv},
  eprint = {1806.09460},
  eprinttype = {arxiv},
  file = {/home/joao/GDRIVE/Zotero/2019-recht-a_tour_of_reinforcement_learning.pdf;/home/joao/GDRIVE/Zotero/2019-recht-a_tour_of_reinforcement_learning2.pdf},
  isbn = {1471-3012},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  keywords = {PT,PT1,R20_1,RL},
  language = {en},
  number = {1}
}

@article{rojas2012a,
  title = {Application of Multivariate Virtual Reference Feedback Tuning for Wastewater Treatment Plant Control},
  author = {Rojas, Jos{\'e} David and {Flores-Alsina}, Xavier and Jeppsson, Ulf and Vilanova, Ram{\'o}n},
  year = {2012},
  volume = {20},
  pages = {499--510},
  issn = {09670661},
  doi = {10.1016/j.conengprac.2012.01.004},
  abstract = {The objective of this paper is to apply the Virtual Reference Feedback Tuning (VRFT) to Multiple-Input Multiple-Output (MIMO) control strategies in wastewater treatment plants (WWTPs). Using the Benchmark Simulation Model No. 1 (BSM1) as a case study, the proposed data-driven approach provides reduced-order controllers only using a batch of input-output data points (i.e. manipulated variable-controlled variable), obtained from an open-loop experiment. The methodology also includes a pre-processing step that subtracts the impact of influent variability and sensor noise from the output signals. The possible interactions amongst different control loops are handled using a decoupling approach where each control signal is computed depending on the error signal of all the loops at the same time. In order to test the methodology, several control strategies are evaluated via simulation. The results show that substantial improvements in the plant performance can be obtained when controllers are implemented. \textcopyright{} 2012 Elsevier Ltd.},
  isbn = {0967-0661},
  journal = {Control Engineering Practice},
  keywords = {BSM1,Control of WWTP,Data-driven control,MIMO control,PT,PT2,Virtual reference feedback tuning},
  number = {5}
}

@article{roman2017a,
  title = {Virtual Reference Feedback Tuning of Model-Free Control Algorithms for Servo Systems},
  author = {Roman, Raul-Cristian and Radac, Mircea-Bogdan and Precup, Radu-Emil and Petriu, Emil},
  year = {2017},
  volume = {5},
  pages = {25},
  issn = {2075-1702},
  doi = {10.3390/machines5040025},
  abstract = {This paper proposes the combination of two data-driven techniques, namely virtual reference feedback tuning (VRFT) and model-Free Control (MFC) in terms of the VRFT of MFC algorithms dedicated to servo systems. VRFT ensures the automatic optimal computation of the parameters of three MFC algorithms represented by intelligent proportional (iP), intelligent proportional-integral (iPI), and intelligent proportional-integral-derivative (iPID) controllers. The combination of MFC and VRFT leads to a novel mixed MFC-VRFT approach. The approach is validated by experimental results related to the angular speed control of modular servo system laboratory equipment. The performance of the control systems with the MFC algorithms (iP, iPI, and iPID controllers) tuned by the mixed MFC-VRFT approach is compared with that of control systems with MFC algorithms tuned by a metaheuristics gravitational search algorithm (GSA) optimizer, and of control systems with I, PI and PID controllers optimally tuned by VRFT and GSA in the same optimization problem.},
  journal = {Machines},
  keywords = {PT,PT2},
  number = {4}
}

@article{safonov1995,
  title = {The Unfalsified Control Concept: {{A}} Direct Path from Experiment to Controller},
  author = {Safonov, Michael G. and Tsao, Tung-Ching},
  year = {1995},
  pages = {196--214},
  issn = {0944-1344},
  doi = {10.1007/BFb0027678},
  abstract = {The philosophical issues pertaining to the problem of going from experiment to controller design are discussed. The ``unfalsified control'' concept is introduced as a framework for determining control laws whose ability to meet given performance specifications is at least not invalidated (i.e., not falsified) by the available data. The approach is ``model-free'' in the sense that no plant model is required \textemdash{} only plant input-output data. When implemented in real time, the result is an adaptive robust controller which modifies itself whenever a new piece of data invalidates the present controller. A simple design example based on fixed-order LTI controllers and an L2-inequality performance criterion is presented.},
  isbn = {1213740444},
  journal = {Feedback Control, Nonlinear Systems, and Complexity},
  keywords = {PT,PT2}
}

@book{saito2018,
  title = {Python Reinforcement Learning Projects Eight Hands-on Projects Exploring Reinforcement Learning Algorithms Using {{TensorFlow}}},
  author = {Saito, Sean and Wenzhuo, Yang and Shanmugamani, Rajalingappaa},
  year = {2018},
  abstract = {Python Reinforcement Learning Projects brings various aspects and methodologies of RL using 8 real-world projects that explore RL and will have hands-on experience with real data and artificial intelligence problems. You will learn to build self-learning models using sophisticated techniques like Q-learning, Markov models and Monte-Carlo process.},
  annotation = {ZSCC: 0000004  OCLC: 1144179038},
  isbn = {978-1-78899-161-2 978-1-78899-322-7},
  keywords = {PT,PT1,RL},
  language = {English}
}

@article{sathiyakeerthi1994,
  title = {A Tutorial Survey of Reinforcement Learning},
  author = {Sathiya Keerthi, S and Ravindran, B},
  year = {1994},
  month = dec,
  volume = {19},
  pages = {851--889},
  issn = {0256-2499, 0973-7677},
  doi = {10/c83b9x},
  annotation = {ZSCC: 0000070},
  file = {/home/joao/GDRIVE/Zotero/1994-sathiya_keerthi_ravindran-a_tutorial_survey_of_reinforcement_learning.pdf},
  journal = {Sadhana},
  keywords = {PT,PT1,R20_1,RL},
  language = {en},
  number = {6}
}

@article{schaal1994,
  title = {Robot Juggling: Implementation of Memory-Based Learning},
  author = {Schaal, Stefan and Atkeson, Christopher G},
  year = {1994},
  month = feb,
  volume = {14},
  pages = {57--71},
  issn = {1066-033X},
  doi = {10.1109/37.257895},
  abstract = {s u e s involved in implementing robot leaming for a challeng-I ing dynamic task are explored in this article, using a case study from robot juggling. We use a memory-based local modeling approach (locally weighted regression) to represent a learned model of the task to be performed. Statistical tests are given to examine the uncertainty of a model, to optimize its prediction quality, and to deal with noisy and corrupted data. We develop an exploration algorithm that explicitly deals with prediction accuracy requirements during exploration. Using all these ingredients in combination with methods from optimal control, our robot achieves fast real-time learning of the task within 40 to 100 trials. Learning Approaches Learning control means improving a motor skill by repeatedly practicing a task. There has been much progress in leaming control research. But many projects test proposed algorithms only in simulation. We have found that actual implementation of learning control forces us to consider issues not adequately addressed in simulations. Here we describe which ingredients were needed to actually implement a learning algorithm on a robot for a complicated dynamic task. We explore systems that learn by explicitly remembering their experiences in order to build models of the world. The learning community distinguishes between two different methods to represent a model, parameti-ic and notiparmietric. A paramerr-ic model consists of a certain mathematical function which possesses a finite set of free parameters that have to be determined to make the function fit the data. This function models all data simultaneously, which means that parametric models correspond to global function fitting. Parametric models and training methods often do not remember the data they were trained on. Standard linear regression, sigmoidal neural networks. radial basis function networks, etc., belong in this class of techniques. Nori-parametiic models also have an underlying function with a set},
  journal = {IEEE Control Systems},
  keywords = {PT,PT2},
  number = {1}
}

@article{shi2000,
  title = {Markov Data-Based {{LQG}} Control},
  author = {Shi, Guojun and Skelton, Robert E},
  year = {2000},
  volume = {122},
  pages = {551},
  issn = {00220434},
  doi = {10.1115/1.1286868},
  journal = {Journal of Dynamic Systems, Measurement, and Control},
  keywords = {digital control,finite horizon optimal control,lqg control,markov parameters,output variance con-,PT,PT2,straint control},
  number = {3}
}

@article{si2001,
  title = {Online Learning Control by Association and Reinforcement},
  author = {Si, J. and {Yu-Tsung Wang}},
  year = {2001},
  month = mar,
  volume = {12},
  pages = {264--276},
  issn = {10459227},
  doi = {10/c7tvgh},
  annotation = {ZSCC: 0000704},
  journal = {IEEE Transactions on Neural Networks},
  keywords = {PT,PT1,R20_1,RL},
  number = {2}
}

@article{simchowitz2018,
  title = {Learning {{Without Mixing}}: {{Towards A Sharp Analysis}} of {{Linear System Identification}}},
  author = {Simchowitz, Max and Mania, Horia and Tu, Stephen and Jordan, Michael I and Recht, Benjamin},
  year = {2018},
  volume = {75},
  pages = {1--35},
  abstract = {We prove that the ordinary least-squares (OLS) estimator attains nearly minimax optimal performance for the identification of linear dynamical systems from a single observed trajectory. Our upper bound relies on a generalization of Mendelson's small-ball method to dependent data, eschewing the use of standard mixing-time arguments. Our lower bounds reveal that these upper bounds match up to logarithmic factors. In particular, we capture the correct signal-to-noise behavior of the problem, showing that more unstable linear systems are easier to estimate. This behavior is qualitatively different from arguments which rely on mixing-time calculations that suggest that unstable systems are more difficult to estimate. We generalize our technique to provide bounds for a more general class of linear response time-series.},
  annotation = {ZSCC: 0000092},
  archivePrefix = {arXiv},
  eprint = {1802.08334},
  eprinttype = {arxiv},
  file = {/home/joao/GDRIVE/Zotero/2018-simchowitz_mania_tu_et_al-learning_without_mixing.pdf},
  journal = {Proceedings of Machine Learning Research},
  keywords = {autoregressive processes,empirical process theory,Linear dynamical systems,PT,PT1,R20_1,RL,system identification,time series}
}

@article{skogestad1997,
  title = {1. {{Strength}} of Earth's Materials},
  author = {Skogestad, Sigurd},
  year = {1997},
  volume = {13},
  pages = {3--8},
  issn = {03327353},
  doi = {10.4173/mic.2004.2.2},
  isbn = {0959-1524},
  keywords = {feedback control,imc,integrating process,pi-control,process control,PT,PT2,time delay}
}

@article{spall1992,
  title = {Multivariate Stochastic Approximation Using a Simultaneous Perturbation Gradient Approximation},
  author = {Spall, J.C.},
  year = {1992},
  month = mar,
  volume = {37},
  pages = {332--341},
  issn = {00189286},
  doi = {10.1109/9.119632},
  abstract = {The problem of finding a root of the multivariate gradient equation that arises in function minimization is considered. When only noisy measurements of the function are available, a stochastic approximation (SA) algorithm for the general Kiefer-Wolfowitz type is appropriate for estimating the root. The paper presents an SA algorithm that is based on a simultaneous perturbation gradient approximation instead of the standard finite-difference approximation of Keifer-Wolfowitz type procedures. Theory and numerical experience indicate that the algorithm can be significantly more efficient than the standard algorithms in large-dimensional problems.},
  isbn = {0-7803-3832-4},
  journal = {IEEE Transactions on Automatic Control},
  keywords = {Experiment design,Optimal probability distribution,Optimization,PT,PT2,SPSA,Stochastic approximation},
  number = {3}
}

@article{sutton1988,
  title = {Learning to Predict by the Methods of Temporal Differences},
  author = {Sutton, Richard S.},
  year = {1988},
  volume = {3},
  pages = {9--44},
  issn = {0885-6125, 1573-0565},
  doi = {10.1007/BF00115009},
  abstract = {This article introduces a class of incremental learning procedures specialized for prediction that is, for using past experience with an incompletely known system to predict its future behavior. Whereas conventional prediction-learning methods assign credit by means of the difference between predicted and actual outcomes, tile new methods assign credit by means of the difference between temporally successive predictions. Although such temporal-difference method\textasciitilde{} have been used in Samuel's checker player, Holland's bucket brigade, and the author's Adaptive Heuristic Critic, they have remained poorly understood. Here we prove their convergence and optimality for special cases and relate them to supervised-learning methods. For most real-world prediction problems, telnporal-differenee methods require less memory and less peak computation than conventional methods and they produce more accurate predictions. We argue that most problems to which supervised learning is currently applied are really prediction problems of the sort to which temporaldifference methods can be applied to advantage.},
  file = {/home/joao/GDRIVE/Zotero/1988-sutton-learning_to_predict_by_the_methods_of_temporal_differences.pdf},
  journal = {Machine Learning},
  keywords = {PT,PT1},
  language = {en},
  number = {1}
}

@book{sutton2018,
  ids = {2018},
  title = {Reinforcement Learning: An Introduction},
  shorttitle = {Reinforcement Learning},
  author = {Sutton, Richard S. and Barto, Andrew G.},
  year = {2018},
  edition = {Second edition},
  publisher = {{The MIT Press}},
  address = {{Cambridge, Massachusetts}},
  abstract = {"Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field's key ideas and algorithms."--},
  isbn = {978-0-262-03924-6},
  keywords = {\#nosource,PT,PT1,R20_1,Reinforcement learning,RL},
  lccn = {Q325.6 .R45 2018},
  series = {Adaptive Computation and Machine Learning Series}
}

@book{takahashi1972,
  title = {Control and {{Dynamic Systems}}},
  author = {Takahashi, Yasundo and Rabins, Michael J and Auslander, David M},
  year = {1972},
  publisher = {{Addison-Wesley}},
  address = {{California}},
  annotation = {ZSCC: 0000003},
  keywords = {\#nosource,PT,PT2}
}

@book{takahashi1972a,
  title = {Control and Dynamic Systems},
  author = {Takahashi, Yasundo and Rabins, Michael J and Auslander, David M},
  year = {1972},
  pages = {800},
  publisher = {{Addison-Wesley}},
  address = {{California}},
  keywords = {PT,PT2}
}

@article{tanaskovic2017a,
  title = {Data-Driven Control of Nonlinear Systems: {{An}} on-Line Direct Approach},
  author = {Tanaskovic, Marko and Fagiano, Lorenzo and Novara, Carlo and Morari, Manfred},
  year = {2017},
  month = jan,
  volume = {75},
  pages = {1--10},
  publisher = {{Pergamon}},
  issn = {00051098},
  doi = {10.1016/j.automatica.2016.09.032},
  abstract = {A data-driven method to design reference tracking controllers for nonlinear systems is presented. The technique does not derive explicitly a model of the system, rather it delivers directly a time-varying state-feedback controller by combining an on-line and an off-line scheme. Like in other on-line algorithms, the measurements collected in closed-loop operation are exploited to modify the controller in order to improve the tracking performance over time. At the same time, a predictable closed-loop behavior is guaranteed by making use of a batch of available data, which is a feature of off-line algorithms. The feedback controller is parameterized with kernel functions and the design approach exploits results in set membership identification and learning by projections. Under the assumptions of Lipschitz continuity and stabilizability of the system's dynamics, it is shown that if the initial batch of data is informative enough, then the resulting closed-loop system is guaranteed to be finite gain stable. In addition to the main theoretical properties of the approach, the design algorithm is demonstrated experimentally on a water tank system.},
  journal = {Automatica},
  keywords = {Adaptive control,Data-driven control,Dynamic inversion,Identification for control,Nonlinear control,PT,PT2}
}

@book{tolle1921,
  title = {Regelung Der {{Kraftmaschienen}}},
  author = {Tolle, Max},
  year = {1921},
  publisher = {{Springer}},
  address = {{Berlin}},
  annotation = {ZSCC: NoCitationData[s0]},
  keywords = {\#nosource,PT,PT2}
}

@book{tolle1921a,
  title = {Regelung Der Kraftmaschienen},
  author = {Tolle, Max},
  year = {1921},
  publisher = {{Springer}},
  address = {{Berlin}},
  keywords = {PT,PT2}
}

@article{umenberger2018a,
  ids = {umenberger2018},
  title = {Learning Convex Bounds for Linear Quadratic Control Policy Synthesis},
  author = {Umenberger, Jack and Sch{\"o}n, Thomas B.},
  year = {2018},
  month = jun,
  abstract = {Learning to make decisions from observed data in dynamic environments remains a problem of fundamental importance in a number of fields, from artificial intelligence and robotics, to medicine and finance. This paper concerns the problem of learning control policies for unknown linear dynamical systems so as to maximize a quadratic reward function. We present a method to optimize the expected value of the reward over the posterior distribution of the unknown system parameters, given data. The algorithm involves sequential convex programing, and enjoys reliable local convergence and robust stability guarantees. Numerical simulations and stabilization of a real-world inverted pendulum are used to demonstrate the approach, with strong performance and robustness properties observed in both.},
  annotation = {ZSCC: 0000005},
  archivePrefix = {arXiv},
  eprint = {1806.00319},
  eprinttype = {arxiv},
  file = {/home/joao/GDRIVE/Zotero/2018-umenberger_schon-learning_convex_bounds_for_linear_quadratic_control_policy_synthesis.pdf;/home/joao/GDRIVE/Zotero/2018-umenberger_schon-learning_convex_bounds_for_linear_quadratic_control_policy_synthesis2.pdf;/home/joao/DADOS/GDRIVE/Zoterocfg/storage/2TMJX687/1806.html},
  journal = {arXiv:1806.00319 [cs, math, stat]},
  keywords = {⛔ No DOI found,Computer Science - Machine Learning,DD,Mathematics - Optimization and Control,PT,PT1,R20_1,RL,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, math, stat}
}

@article{umenberger2019,
  ids = {umenberger2019a},
  title = {Robust Exploration in Linear Quadratic Reinforcement Learning},
  author = {Umenberger, Jack and Ferizbegovic, Mina and Sch{\"o}n, Thomas B. and Hjalmarsson, H{\aa}kan},
  year = {2019},
  month = jun,
  abstract = {This paper concerns the problem of learning control policies for an unknown linear dynamical system to minimize a quadratic cost function. We present a method, based on convex optimization, that accomplishes this task robustly: i.e., we minimize the worst-case cost, accounting for system uncertainty given the observed data. The method balances exploitation and exploration, exciting the system in such a way so as to reduce uncertainty in the model parameters to which the worst-case cost is most sensitive. Numerical simulations and application to a hardware-in-the-loop servo-mechanism demonstrate the approach, with appreciable performance and robustness gains over alternative methods observed in both.},
  annotation = {ZSCC: 0000008},
  archivePrefix = {arXiv},
  eprint = {1906.01584},
  eprinttype = {arxiv},
  file = {/home/joao/GDRIVE/Zotero/2019-umenberger_ferizbegovic_schon_hjalmarsson-robust_exploration_in_linear_quadratic_reinforcement_learning.pdf},
  journal = {arXiv:1906.01584 [cs, math, stat]},
  keywords = {Computer Science - Machine Learning,DD,Folder - RL,Mathematics - Optimization and Control,PT,PT1,RL,Statistics - Machine Learning},
  language = {en},
  primaryClass = {cs, math, stat}
}

@inproceedings{vamvoudakis2011,
  title = {Online Adaptive Learning of Optimal Control Solutions Using Integral Reinforcement Learning},
  booktitle = {2011 {{IEEE Symposium}} on {{Adaptive Dynamic Programming}} and {{Reinforcement Learning}} ({{ADPRL}})},
  author = {Vamvoudakis, Kyriakos G. and Vrabie, Draguna and Lewis, Frank L.},
  year = {2011},
  month = apr,
  pages = {250--257},
  issn = {2325-1867},
  doi = {10/fj84tj},
  abstract = {In this paper we introduce an online algorithm that uses integral reinforcement knowledge for learning the continuous-time optimal control solution for nonlinear systems with infinite horizon costs and partial knowledge of the system dynamics. This algorithm is a data based approach to the solution of the Hamilton-Jacobi-Bellman equation and it does not require explicit knowledge on the system's drift dynamics. The adaptive algorithm is based on policy iteration, and it is implemented on an actor/critic structure. Both actor and critic neural networks are adapted simultaneously a persistence of excitation condition is required to guarantee convergence of the critic to the actual optimal value function. Novel tuning algorithms are given for both critic and actor networks, with extra terms in the actor tuning law being required to guarantee closed-loop dynamical stability. The convergence to the optimal controller is proven, and stability of the system is also guaranteed. Simulation examples support the theoretical result.},
  annotation = {ZSCC: 0000012},
  file = {/home/joao/GDRIVE/Zotero/2011-vamvoudakis_vrabie_lewis-online_adaptive_learning_of_optimal_control_solutions_using_integral.pdf;/home/joao/DADOS/GDRIVE/Zoterocfg/storage/JMJ3N5RW/5967359.html},
  keywords = {actor neural networks,adaptive control,closed loop systems,closed-loop dynamical stability,continuous time systems,continuous-time optimal control solution,critic neural networks,Hamilton-Jacobi-Bellman equation,infinite horizon costs,integral reinforcement knowledge,integral reinforcement learning,iterative methods,Jacobian matrices,learning (artificial intelligence),learning systems,neurocontrollers,nonlinear control systems,nonlinear systems,online adaptive learning,optimal control,policy iteration,PT,PT1,RL,stability,system dynamics,tuning algorithms}
}

@article{vanheusden2011a,
  title = {Data-Driven Model Reference Control with Asymptotically Guaranteed Stability},
  author = {{van Heusden}, Klaske and Karimi, Alireza and Bonvin, Dominique},
  year = {2011},
  volume = {25},
  pages = {331--351},
  issn = {0890-6327},
  doi = {10.1002/acs.1212},
  abstract = {This paper presents a data-driven controller tuning method that includes a set of constraints for ensuring closed-loop stability. The approach requires a single experiment and can also be applied to nonminimum-phase and unstable systems. The tuning scheme generates an estimate of the closed-loop output error that is used to minimize an approximation of the model reference control problem. The correlation approach is used to deal with the influence of measurement noise. For linearly parameterized controllers, this leads to a convex optimization problem. A sufficient condition for closed-loop stability is introduced, which can be included in the optimization problem for control design. As the data length tends to infinity, closed-loop stability is guaranteed. The quality of the estimated controller is analyzed for finite data length. The effectiveness of the proposed method is demonstrated in simulation as well as experimentally on a laboratory-scale mechanical setup. Copyright (C) 2010 John Wiley \& Sons, Ltd.},
  journal = {INTERNATIONAL JOURNAL OF ADAPTIVE CONTROL AND SIGNAL PROCESSING},
  keywords = {PT,PT2},
  number = {4}
}

@book{vrabie2013,
  title = {Optimal Adaptive Control and Differential Games by Reinforcement Learning Principles},
  author = {Vrabie, Draguna L.},
  year = {2013},
  publisher = {{The Institution of Engineering and Technology}},
  address = {{London}},
  annotation = {ZSCC: NoCitationData[s1]},
  collaborator = {{Institution of Engineering {and} Technology}},
  isbn = {978-1-84919-489-1},
  keywords = {Adaptive control systems,PT,PT1,RL},
  lccn = {MLCM 2017/45857 (T)},
  number = {81},
  series = {{{IET}} Control Engineering Series}
}

@article{waltz1965,
  title = {A Heuristic Approach to Reinforcement Learning Control Systems},
  author = {Waltz, M. and Fu, K.},
  year = {1965},
  volume = {10},
  pages = {390--398},
  issn = {1558-2523},
  doi = {10.1109/TAC.1965.1098193},
  abstract = {This paper describes a learning control system using a reinforcement technique. The controller is capable of controlling a plant that may be nonlinear and nonstationary. The only a priori information required by the controller is the order of the plant. The approach is to design a controller which partitions the control measurement space into sets called control situations and then learns the best control choice for each control situation. The control measurements are those indicating the state of the plant and environment. The learning is accomplished by reinforcement of the probability of choosing a particular control choice for a given control situation. The system was stimulated on an IBM 1710-GEDA hybrid computer facility. Experimental results obtained from the simulation are presented.},
  file = {/home/joao/DADOS/GDRIVE/Zoterocfg/storage/I5CXTA2P/www.periodicos.capes.gov.br.html},
  journal = {IEEE Transactions on Automatic Control},
  keywords = {Adaptive control,Application software,Automatic control,Computational modeling,Control systems,Differential equations,Extraterrestrial measurements,Learning,Learning control systems,Programmable control,PT,PT1,State-space methods},
  number = {4}
}

@inproceedings{wang2011a,
  title = {{{PID}} Controller Design of Based on Neural Network and Virtual Reference Feedback Tuning},
  booktitle = {2011 {{CHINESE CONTROL AND DECISION CONFERENCE}}, {{VOLS}} 1-6},
  author = {Wang, Jing},
  year = {2011},
  pages = {3078--3083},
  issn = {1948-9439},
  abstract = {The paper presents a method of data-driven parameter setting based on neural network, which is aimed at the nonlinear controlled objects, and these objects are difficult to establish accurate mathematical model. The network connection weights and node threshold are adjusted to identify the controller parameters by comparison of the virtual reference feedback tuning performance, and this idea can skip the controlled object modeling process. Also, the relationship between VRFT and IMC is derived. In addition;. the paper matte the proof of neural network learning rate can guarantee Convergence of precise tracking error within limits, and also combined the VRFT parameters to prove the stability of the closed-loop system. Simulation shows that this method has some characteristics, such as strong tracking performance, fast response, good control results for nonlinear plant and so on.},
  isbn = {978-1-4244-8736-3},
  keywords = {PT,PT2},
  series = {Chinese Control and Decision Conference}
}

@phdthesis{watkins1989,
  title = {Learning from {{Delayed Rewards}}},
  author = {Watkins, Christopher J. C. H.},
  year = {1989},
  address = {{Cambridge}},
  file = {/home/joao/GDRIVE/Zotero/1989-watkins-learning_from_delayed_rewards.pdf},
  keywords = {PT,PT1},
  school = {University of Cambridge},
  type = {Ph.{{D}}. Thesis}
}

@article{watkins1992,
  title = {Q-Learning},
  author = {Watkins, Christopher J. C. H. and Dayan, Peter},
  year = {1992},
  volume = {8},
  pages = {279--292},
  issn = {0885-6125},
  doi = {10.1007/bf00992698},
  abstract = {Q-learning (Watkins, 1989) is a simple way for agents to learn how to act optimally in controlled Markovian domains. It amounts to an incremental method for dynamic programming which imposes limited computational demands. It works by successively improving its evaluations of the quality of particular actions at particular states. This paper presents and proves in detail a convergence theorem forQ-learning based on that outlined in Watkins (1989). We show thatQ-learning converges to the optimum action-values with probability 1 so long as all actions are repeatedly sampled in all states and the action-values are represented discretely. We also sketch extensions to the cases of non-discounted, but absorbing, Markov environments, and where manyQ values can be changed each iteration, rather than just one.},
  annotation = {ZSCC: 0010899},
  file = {/home/joao/GDRIVE/Zotero/1992-watkins_dayan-q-learning.pdf},
  journal = {Machine Learning},
  keywords = {-learning,asynchronous dynamic programming,PT,PT1,R20_1,reinforcement learning,RL,temporal differences},
  number = {3-4}
}

@article{webofscience2018,
  title = {Web of Science},
  author = {{Web of Science}},
  year = {2018},
  keywords = {PT,PT2}
}

@article{wen2018,
  ids = {OptimizedBacksteppingTracking2018,Wen2018,wen2018a,wen2018b,wen2018c,wen2018d},
  title = {Optimized {{Backstepping}} for {{Tracking Control}} of {{Strict}}-{{Feedback Systems}}},
  author = {Wen, Guoxing and Ge, Shuzhi Sam and Tu, Fangwen},
  year = {2018},
  month = aug,
  volume = {29},
  pages = {3850--3862},
  publisher = {{IEEE}},
  issn = {2162-237X},
  doi = {10.1109/TNNLS.2018.2803726},
  abstract = {In this paper, a control technique named optimized backstepping is first proposed by implementing tracking control for a class of strict-feedback systems, which considers optimization as a design philosophy of the high-order system control. The basic idea is that designing the actual and virtual controls of backstepping is the optimized solutions of the corresponding subsystems so that overall control of the high-order system is optimized. In general, optimization control is designed based on the solution of Hamilton-Jacobi-Bellman equation, but solving the equation is very difficult due to the inherent nonlinearity and intractability. In order to overcome the difficulty, the neural network (NN)-based reinforcement learning strategy of actor-critic architecture is used. In every backstepping step, the actor and critic NNs are constructed for executing control behavior and evaluating control performance, respectively. According to the Lyapunov stability theorem, it is proven that the desired control performance can be obtained. Finally, a simulation example is carried out to further demonstrate the effectiveness of the proposed control approach.},
  annotation = {ZSCC: 0000031},
  file = {/home/joao/GDRIVE/Zotero/2018-wen_ge_tu-optimized_backstepping_for_tracking_control_of_strict-feedback_systems.pdf},
  journal = {IEEE Transactions on Neural Networks and Learning Systems},
  keywords = {actor-critic,Backstepping,Lyapunov stability,optimized backstepping (OB),PT,PT1,R20_1,RL,strict-feedback system,TCNL,tracking control},
  number = {8}
}

@article{xie2018a,
  title = {Data-Driven Adaptive Fractional Order {{PI}} Control for {{PMSM}} Servo System with Measurement Noise and Data Dropouts},
  author = {Xie, Yuanlong and Tang, Xiaoqi and Song, Bao and Zhou, Xiangdong and Guo, Yixuan},
  year = {2018},
  volume = {75},
  pages = {172--188},
  publisher = {{Elsevier Ltd}},
  issn = {00190578},
  doi = {10.1016/j.isatra.2018.02.018},
  abstract = {In this paper, data-driven adaptive fractional order proportional integral (AFOPI) control is presented for permanent magnet synchronous motor (PMSM) servo system perturbed by measurement noise and data dropouts. The proposed method directly exploits the closed-loop process data for the AFOPI controller design under unknown noise distribution and data missing probability. Firstly, the proposed method constructs the AFOPI controller tuning problem as a parameter identification problem using the modified lpnorm virtual reference feedback tuning (VRFT). Then, iteratively reweighted least squares is integrated into the lpnorm VRFT to give a consistent compensation solution for the AFOPI controller. The measurement noise and data dropouts are estimated and eliminated by feedback compensation periodically, so that the AFOPI controller is updated online to accommodate the time-varying operating conditions. Moreover, the convergence and stability are guaranteed by mathematical analysis. Finally, the effectiveness of the proposed method is demonstrated both on simulations and experiments implemented on a practical PMSM servo system.},
  journal = {ISA Transactions},
  keywords = {AFOPI controller,Data dropouts,Iteratively reweighted least squares,lpnorm VRFT,Measurement noise,PMSM servo system,PT,PT2}
}

@article{yan2016a,
  title = {Data-Driven Controller Design for General {{MIMO}} Nonlinear Systems via Virtual Reference Feedback Tuning and Neural Networks},
  author = {Yan, Pengfei and Liu, Derong and Wang, Ding and Ma, Hongwen},
  year = {2016},
  month = jan,
  volume = {171},
  pages = {815--825},
  issn = {09252312},
  doi = {10.1016/j.neucom.2015.07.017},
  abstract = {In this paper, we develop a novel data-driven multivariate nonlinear controller design method for multi-input-multi-output (MIMO) nonlinear systems via virtual reference feedback tuning (VRFT) and neural networks. To the best of authors' knowledge, it is the first time to introduce VRFT to MIMO nonlinear systems in theory. Unlike the standard VRFT for linear systems, we restate the model reference control problem with time-domain model in the absence of transfer functions and simplify the objective function of VRFT without a linear filter. Then, we prove that the objective function of VRFT reaches the minimum at the same point as the optimization problem of model reference control and give the relationship between the bounds of the two optimization problems of model reference control and VRFT. A three-layer neural network is used to implement the developed method. Finally, two simulations are conducted to verify the validity of our method.},
  journal = {Neurocomputing},
  keywords = {Data-driven control,MIMO nonlinear systems,Model reference control,Neural networks,PT,PT2,Virtual reference feedback tuning}
}

@article{yin2015a,
  title = {Data-Based Techniques Focused on Modern Industry: {{An}} Overview},
  author = {Yin, Shen and Li, Xianwei and Gao, Huijun and Kaynak, Okyay},
  year = {2015},
  month = jan,
  volume = {62},
  pages = {657--667},
  issn = {0278-0046},
  doi = {10.1109/TIE.2014.2308133},
  abstract = {This paper provides an overview of the recent developments in data-based techniques focused on modern industrial applications. As one of the hottest research topics for complicated processes, the data-based techniques have been rapidly developed over the past two decades and widely used in numerous industrial sectors nowadays. The core of data-based techniques is to take full advantage of the huge amounts of available process data, aiming to acquire the useful information within. Compared with the well-developed model-based approaches, data-based techniques provide efficient alternative solutions for different industrial issues under various operating conditions. The main objective of this paper is to review and summarize the recent achievements in data-based techniques, especially for complicated industrial applications, thus providing a referee for further study on the related topics both from academic and practical points of view. This paper begins with a brief evolutionary overview of data-based techniques in the last two decades. Then, the methodologies only based on process measurements and the model-data integrated techniques will be further introduced. The recent developments for modern industrial applications are, respectively, presented mainly from perspectives of monitoring and control. The new trends of data-based technique as well as potential application fields are finally discussed.},
  isbn = {0278-0046},
  journal = {IEEE Transactions on Industrial Electronics},
  keywords = {Complicated industrial applications,data-based techniques,monitoring and control,overview,PT,PT2},
  number = {1}
}

@techreport{zhang1992,
  title = {Analysing the Transfer Functions of Nonlinear Systems in the Frequency Domain},
  author = {Zhang, H . and Billings, S . A .},
  year = {1992},
  address = {{Sheffield, U.K.}},
  institution = {{University of Sheffield}},
  keywords = {PT,PT2}
}

@article{zhang2011a,
  title = {Data-Driven Robust Approximate Optimal Tracking Control for Unknown General Nonlinear Systems Using Adaptive Dynamic Programming Method},
  author = {Zhang, Huaguang and Cui, Lili and Zhang, Xin and Luo, Yanhong},
  year = {2011},
  volume = {22},
  pages = {2226--2236},
  issn = {10459227},
  doi = {10.1109/TNN.2011.2168538},
  abstract = {In this paper, a novel data-driven robust approximate optimal tracking control scheme is proposed for unknown general nonlinear systems by using the adaptive dynamic programming (ADP) method. In the design of the controller, only available input-output data is required instead of known system dynamics. A data-driven model is established by a recurrent neural network (NN) to reconstruct the unknown system dynamics using available input-output data. By adding a novel adjustable term related to the modeling error, the resultant modeling error is first guaranteed to converge to zero. Then, based on the obtained data-driven model, the ADP method is utilized to design the approximate optimal tracking controller, which consists of the steady-state controller and the optimal feedback controller. Further, a robustifying term is developed to compensate for the NN approximation errors introduced by implementing the ADP method. Based on Lyapunov approach, stability analysis of the closed-loop system is performed to show that the proposed controller guarantees the system state asymptotically tracking the desired trajectory. Additionally, the obtained control input is proven to be close to the optimal control input within a small bound. Finally, two numerical examples are used to demonstrate the effectiveness of the proposed control scheme.},
  isbn = {1941-0093 (Electronic) 1045-9227 (Linking)},
  journal = {IEEE Transactions on Neural Networks},
  keywords = {Adaptive dynamic programming,data-driven model,neural networks,optimal tracking control,PT,PT2,robust control},
  number = {12 PART 2},
  pmid = {21997259}
}

@article{zhu2015a,
  title = {Controller Dynamic Linearisation-Based Model-Free Adaptive Control Framework for a Class of Non-Linear System},
  author = {Zhu, Yuanming and Hou, Zhongsheng},
  year = {2015},
  volume = {9},
  pages = {1162--1172},
  issn = {1751-8644},
  doi = {10.1049/iet-cta.2014.0743},
  abstract = {Without the explicit process identification, the authors propose a model-free adaptive control framework for unknown plant by using the concept of equivalent dynamic linearisation controller. The controller has linear incremental structure and its local dynamics is equivalent to the ideal controller in theory. Hence, the problem of determining the structure of candidate controller is transformed to the problem of finding a sequence of local dynamic controllers to approximate the ideal controller. With the help of gradient information extracted from input and output (I/O) data of the plant, the optimal controller parameter sequence is generated by minimising a user-defined control criterion. This method gives a solution on how to determine the candidate controller structure. The controller design, parameter tuning and controller validation are based on I/O data of the plant. Hence, it could reduce the influence of internal disturbance or unmodelled dynamics. The effectiveness of the proposed method is illustrated by the simulation of a continuous polymerisation reaction process in a jacketed continuous stirred tank reactor system. Meanwhile, a simulation comparison is carried out to show the superiority of neural network data model in model-free adaptive control framework.},
  journal = {IET CONTROL THEORY AND APPLICATIONS},
  keywords = {PT,PT2},
  number = {7}
}

@article{ziegler1942,
  title = {Optimum Settings for Automatic Controllers},
  author = {Ziegler, J G and Nichols, N B},
  year = {1942},
  volume = {64},
  pages = {759--768},
  journal = {Transactions of ASME},
  keywords = {PT,PT2}
}

@article{ziegler1995,
  title = {Optimum Settings for Automatic Controllers},
  author = {Ziegler, J. G. and Nichols, N. B.},
  year = {1995},
  volume = {42},
  pages = {94--100},
  issn = {0192303X},
  doi = {10.1115/1.2899060},
  abstract = {In this paper, the three principal control effects found in present controllers are examined and practical names and units of measurement are proposed for each effect. Corresponding units are proposed for a classification of industrial processes in terms of the two principal characteristics affecting their controllability. Formulas are given which enable the controller settings to be determined from the experimental or calculated values of the lag and unit reaction rate of the process to be controlled. These units form the basis of a quick method for adjusting a controller on the job. The effect of varying each controller setting is shown in a series of chart records. It is believed that the conceptions of control presented in this paper will be of assistance in the adjustment of existing controller applications and in the design of new installations.},
  isbn = {0022-0434},
  journal = {InTech},
  keywords = {PT,PT2},
  number = {6}
}


